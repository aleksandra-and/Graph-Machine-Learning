{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "is5ZiquMgj5j",
    "Nt6BQK32gMN1"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 13424334,
     "sourceType": "datasetVersion",
     "datasetId": 8520408
    }
   ],
   "dockerImageVersionId": 31153,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:32.206908Z",
     "start_time": "2025-10-30T13:31:32.200483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these variables for different experiments\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Data paths\n",
    "dir_local = '/home/study/IdeaProjects/Graph-Machine-Learning/Temporal_RSR/data'\n",
    "dir_kaggle = '/kaggle/input/rsr-dataset/Data/'\n",
    "\n",
    "# ============================================================================\n",
    "# EXPERIMENT CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Dataset parameters\n",
    "num_companies = 1026  # max is 1026\n",
    "num_days = 1245\n",
    "num_features = 5\n",
    "market = \"NASDAQ\"  # or \"NYSE\"\n",
    "\n",
    "# Temporal parameters\n",
    "window_size = 20  # Lookback period for temporal models\n",
    "prediction_horizon = 1  # How many days ahead to predict\n",
    "\n",
    "# Train/Val/Test split (should sum to 1.0)\n",
    "train_split = 0.8  # 80% for training\n",
    "val_split = 0.1    # 10% for validation\n",
    "test_split = 0.1   # 10% for test\n",
    "\n",
    "# Graph parameters\n",
    "K = 5  # Number of graph hops for GNN models\n",
    "calculate_correlation = False\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL CONFIGURATION - Activate/Deactivate features\n",
    "# ============================================================================\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    # Which model to train\n",
    "    'use_gvar': False,      # Simple G-VAR baseline\n",
    "    'use_gcn': False,       # Pure GCN model\n",
    "    'use_gat': True,        # GAT model (attention-based)\n",
    "    \n",
    "    # Graph features\n",
    "    'use_industry_relations': True,   # Use industry relationship data\n",
    "    'use_wiki_relations': True,       # Use Wikipedia relationship data\n",
    "    'use_graph_structure': True,      # If False, uses identity matrix (no graph)\n",
    "    'separate_edge_weights': True,   # If True, use 2D edge features [industry_wt, wiki_wt]\n",
    "    \n",
    "    # Model architecture\n",
    "    'hidden_dim': 15,                 # Hidden layer dimension\n",
    "    'num_attention_heads': 3,         # For GAT model\n",
    "    'dropout': 0.0,                   # Dropout rate\n",
    "    'use_relu_output': False,         # Apply ReLU after final GAT layer (False for regression)\n",
    "    'use_batched_gat': True,          # Use faster batched GAT processing (100-1000x faster!)\n",
    "    \n",
    "    # Training parameters\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 0.0,              # L2 regularization\n",
    "    'batch_training': False,          # If True, use mini-batches (not implemented yet)\n",
    "    \n",
    "    # Feature engineering\n",
    "    'normalize_features': False,      # Normalize input features\n",
    "    'use_all_features': True,         # Use all 5 stock features\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "train_batch = 1\n",
    "val_batch = 1\n",
    "epochs = 1000\n",
    "val_min_num = 10\n",
    "use_kfold = False\n",
    "early_stopping_patience = 1000  # Stop if no improvement for N epochs\n",
    "\n",
    "# Environment detection\n",
    "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "    print(\"Running on Kaggle!\")\n",
    "    dir = dir_kaggle\n",
    "    train_batch = 32\n",
    "    val_batch = 32\n",
    "    epochs = 100\n",
    "    num_companies = 1026\n",
    "    calculate_correlation = True\n",
    "else:\n",
    "    dir = dir_local\n",
    "    print(\"Running locally!\")\n",
    "\n",
    "SAVE_PREPROCESSED_DATA = False  # Set to True to save preprocessed data\n",
    "\n",
    "# ============================================================================\n",
    "# PRINT CONFIGURATION SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"EXPERIMENT CONFIGURATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Dataset:\")\n",
    "print(f\"  Market: {market}\")\n",
    "print(f\"  Companies: {num_companies}\")\n",
    "print(f\"  Features: {num_features}\")\n",
    "print(f\"  Window size: {window_size}\")\n",
    "print(f\"  Prediction horizon: {prediction_horizon}\")\n",
    "\n",
    "print(f\"\\nData Split:\")\n",
    "print(f\"  Train: {train_split*100:.0f}%\")\n",
    "print(f\"  Val:   {val_split*100:.0f}%\")\n",
    "print(f\"  Test:  {test_split*100:.0f}%\")\n",
    "\n",
    "print(f\"\\nModel Configuration:\")\n",
    "active_model = [k.replace('use_', '').upper() for k, v in MODEL_CONFIG.items() if k.startswith('use_') and v and k in ['use_gvar', 'use_gcn', 'use_gat']]\n",
    "print(f\"  Active model: {active_model[0] if active_model else 'NONE'}\")\n",
    "print(f\"  Graph structure: {'Yes' if MODEL_CONFIG['use_graph_structure'] else 'No (identity)'}\")\n",
    "print(f\"  Industry relations: {'Yes' if MODEL_CONFIG['use_industry_relations'] else 'No'}\")\n",
    "print(f\"  Wiki relations: {'Yes' if MODEL_CONFIG['use_wiki_relations'] else 'No'}\")\n",
    "print(f\"  Separate edge weights: {'Yes (2D)' if MODEL_CONFIG['separate_edge_weights'] else 'No (1D combined)'}\")\n",
    "print(f\"  Hidden dim: {MODEL_CONFIG['hidden_dim']}\")\n",
    "print(f\"  Learning rate: {MODEL_CONFIG['learning_rate']}\")\n",
    "print(f\"  ReLU on output: {'Yes' if MODEL_CONFIG['use_relu_output'] else 'No (better for regression)'}\")\n",
    "print(f\"  Batched GAT: {'Yes (fast!)' if MODEL_CONFIG['use_batched_gat'] else 'No (slow)'}\")\n",
    "\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  Epochs: {epochs}\")\n",
    "print(f\"  Graph hops (K): {K}\")\n",
    "print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
    "print(f\"{'='*60}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally!\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT CONFIGURATION\n",
      "============================================================\n",
      "Dataset:\n",
      "  Market: NASDAQ\n",
      "  Companies: 1026\n",
      "  Features: 5\n",
      "  Window size: 20\n",
      "  Prediction horizon: 1\n",
      "\n",
      "Data Split:\n",
      "  Train: 80%\n",
      "  Val:   10%\n",
      "  Test:  10%\n",
      "\n",
      "Model Configuration:\n",
      "  Active model: GAT\n",
      "  Graph structure: Yes\n",
      "  Industry relations: Yes\n",
      "  Wiki relations: Yes\n",
      "  Separate edge weights: Yes (2D)\n",
      "  Hidden dim: 15\n",
      "  Learning rate: 0.001\n",
      "  ReLU on output: No (better for regression)\n",
      "  Batched GAT: Yes (fast!)\n",
      "\n",
      "Training:\n",
      "  Epochs: 1000\n",
      "  Graph hops (K): 5\n",
      "  Early stopping patience: 1000\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "source": "# Stock Prediction with Graph Neural Networks\n\n## üéØ Quick Start Guide\n\n### Running Different Experiments\n\nAll experiments are controlled from **Cell 1 (Configuration)**. Simply modify the values and restart the kernel:\n\n```python\n# Example 1: Test with fewer companies\nnum_companies = 50\nwindow_size = 20\nMODEL_CONFIG['use_gat'] = True\n\n# Example 2: Disable graph structure (baseline)\nMODEL_CONFIG['use_graph_structure'] = False\n\n# Example 3: Use only industry relations\nMODEL_CONFIG['use_wiki_relations'] = False\nMODEL_CONFIG['use_industry_relations'] = True\n\n# Example 4: Try different model\nMODEL_CONFIG['use_gat'] = False\nMODEL_CONFIG['use_gcn'] = True\n```\n\n### Key Configuration Options\n\n**MODEL_CONFIG dictionary:**\n- `use_gvar`, `use_gcn`, `use_gat`: Choose which model to train\n- `use_graph_structure`: Set to False for baseline (no graph)\n- `use_industry_relations`: Include/exclude industry relationship data\n- `use_wiki_relations`: Include/exclude Wikipedia relationship data\n- `hidden_dim`: Size of hidden layers\n- `learning_rate`: Optimizer learning rate\n- `dropout`: Regularization parameter\n\n**Data splits:**\n- `train_split = 0.8`: 80% of timesteps for training\n- `val_split = 0.1`: 10% for validation\n- `test_split = 0.1`: 10% for testing\n- All splits preserve temporal order (no shuffling!)\n\n---\n\n## üìÅ Notebook Structure\n\n### 1. Configuration (Cell 1)\n- **Modify this cell** to control all experiments\n- `MODEL_CONFIG` dictionary for feature flags\n- Train/val/test split ratios\n- All hyperparameters in one place\n\n### 2. Dependencies & Setup (Cells 2-3)\n- Package installation and imports\n- Device detection (CPU/GPU)\n\n### 3. Data Loading Functions (Cells 4-5)\n- `load_EOD_data()`: Load stock price data\n- `load_relation_data()`: Load company relationship data\n\n### 4. Data Loading (Cells 6-12)\n- Load market data (NASDAQ/NYSE)\n- Load company relationships (industry, wiki)\n- **Subsample to `num_companies`** (Cell 12)\n\n### 5. Utility Functions (Cell 15)\n- `build_adjacency_matrix()`: Create normalized adjacency (respects config flags)\n- `build_graph_shift_operator()`: Create GCN-style normalization\n- `prepare_data()`: Create sliding window datasets\n- `temporal_train_val_test_split()`: **Split by time** (80/10/10)\n- `calculate_loss()`: Masked loss computation\n\n### 6. Data Preparation (Cells 17-18)\n- Convert to PyTorch tensors\n- Build graph structures (respects config flags)\n- Create training data with sliding windows\n- **Split into train/val/test** temporally\n\n### 7. Model Definitions (Cells 19-26)\n- **GVarModel** (Cell 20): Vector autoregression baseline\n- **GCNModel** (Cell 24): Graph convolutional network\n- **GCNGATModel** (Cell 26): Graph attention network\n\n### 8. Training & Evaluation (Cells 27-28)\n- **Cell 27**: Full training loop with:\n  - Train/validation monitoring\n  - Early stopping\n  - Test set evaluation\n  - Best model selection\n- **Cell 28**: Training visualization (loss curves)\n\n---\n\n## ‚úÖ Feature Verification\n\nThe notebook **automatically verifies** that all 5 stock features are being used:\n- Opens: High, Low, Close, Adj Close, Volume\n- Check output in Cell 27 for confirmation\n\n---\n\n## üß™ Testing Different Configurations\n\n### Example 1: Ablation Study (Graph vs No Graph)\n\n**Step 1:** With graph structure\n```python\nMODEL_CONFIG['use_graph_structure'] = True\n```\n\n**Step 2:** Without graph structure (baseline)\n```python\nMODEL_CONFIG['use_graph_structure'] = False  # Uses identity matrix\n```\n\nRestart kernel and compare test set performance!\n\n### Example 2: Relation Type Comparison\n\nTest which relations help more:\n```python\n# Only industry\nMODEL_CONFIG['use_industry_relations'] = True\nMODEL_CONFIG['use_wiki_relations'] = False\n\n# Only wiki\nMODEL_CONFIG['use_industry_relations'] = False\nMODEL_CONFIG['use_wiki_relations'] = True\n\n# Both (default)\nMODEL_CONFIG['use_industry_relations'] = True\nMODEL_CONFIG['use_wiki_relations'] = True\n```\n\n### Example 3: Model Comparison\n\n```python\n# Test GAT\nMODEL_CONFIG['use_gat'] = True\nMODEL_CONFIG['use_gcn'] = False\nMODEL_CONFIG['use_gvar'] = False\n\n# Test GCN (uncomment alternative training cells)\nMODEL_CONFIG['use_gat'] = False\nMODEL_CONFIG['use_gcn'] = True\n```\n\n### Example 4: Hyperparameter Tuning\n\n```python\nMODEL_CONFIG['learning_rate'] = 0.0001  # Lower LR\nMODEL_CONFIG['hidden_dim'] = 32         # Bigger model\nMODEL_CONFIG['dropout'] = 0.3           # Less regularization\nepochs = 100                             # More training\n```\n\n---\n\n## üìä Understanding the Output\n\n### Training Progress\n```\nEpoch [  1/20] | Train Loss: 0.328155 | Val Loss: 0.350221\n```\n- **Train Loss**: MSE on training data\n- **Val Loss**: MSE on validation data (used for early stopping)\n\n### Final Evaluation\n```\nFinal MSE Loss:\n  Train: 0.045123\n  Val:   0.052341\n  Test:  0.048765\n```\n- **Test Loss**: Performance on unseen future timesteps\n- Lower is better!\n\n### RMSE (Root Mean Squared Error)\nMore interpretable than MSE - in same units as stock prices.\n\n---\n\n## üí° Tips\n\n1. **Always restart kernel** when changing configuration\n2. **Use temporal split** - never shuffle time series data!\n3. **Check validation loss** - if much higher than train loss ‚Üí overfitting\n4. **Early stopping** prevents overtraining (patience = 20 epochs)\n5. **Test set is sacred** - only look at it for final evaluation!\n\n---",
   "metadata": {}
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:33.614915Z",
     "start_time": "2025-10-30T13:31:32.252139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%pip install torch-geometric\n",
    "%pip install statsmodels\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1 of /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages/distutils-precedence.pth:\r\n",
      "\r\n",
      "  Traceback (most recent call last):\r\n",
      "    File \"<frozen site>\", line 195, in addpackage\r\n",
      "    File \"<string>\", line 1, in <module>\r\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\r\n",
      "\r\n",
      "Remainder of file ignored\r\n",
      "Requirement already satisfied: torch-geometric in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (2.6.1)\r\n",
      "Requirement already satisfied: aiohttp in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (3.12.15)\r\n",
      "Requirement already satisfied: fsspec in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (2025.9.0)\r\n",
      "Requirement already satisfied: jinja2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: numpy in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (2.0.1)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (7.1.0)\r\n",
      "Requirement already satisfied: pyparsing in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (3.2.5)\r\n",
      "Requirement already satisfied: requests in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (2.32.5)\r\n",
      "Requirement already satisfied: tqdm in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (4.67.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (6.6.4)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (0.4.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.21.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from jinja2->torch-geometric) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (2025.10.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Error processing line 1 of /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages/distutils-precedence.pth:\r\n",
      "\r\n",
      "  Traceback (most recent call last):\r\n",
      "    File \"<frozen site>\", line 195, in addpackage\r\n",
      "    File \"<string>\", line 1, in <module>\r\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\r\n",
      "\r\n",
      "Remainder of file ignored\r\n",
      "Requirement already satisfied: statsmodels in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (0.14.5)\r\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (2.0.1)\r\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (1.16.2)\r\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (2.3.3)\r\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (1.0.1)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (25.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# IMPORTS\n# ============================================================================\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport networkx as nx\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom torch_geometric.nn import GATConv\nimport os\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Using device:\", device)",
   "metadata": {
    "id": "9j8W6h4rkMKv",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:25.354718Z",
     "iopub.execute_input": "2025-10-29T17:53:25.354874Z",
     "iopub.status.idle": "2025-10-29T17:53:29.553412Z",
     "shell.execute_reply.started": "2025-10-29T17:53:25.354862Z",
     "shell.execute_reply": "2025-10-29T17:53:29.552648Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:33.763072Z",
     "start_time": "2025-10-30T13:31:33.760325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCOPIED FROM THE PAPER\nsource code: https://github.com/fulifeng/Temporal_Relational_Stock_Ranking\n\"\"\"\ndef load_EOD_data(data_path, market_name, tickers, steps=1):\n    eod_data = []\n    masks = []\n    ground_truth = []\n    base_price = []\n\n    # Determine the expected number of rows based on the first ticker's data\n    first_ticker_path = os.path.join(data_path, market_name + '_' + tickers[0] + '_1.csv')\n    try:\n        first_df = pd.read_csv(first_ticker_path, header=None)\n        num_days = first_df.shape[0] - (1 if market_name == 'NASDAQ' else 0) # Remove last row for NASDAQ\n        num_features = first_df.shape[1] - 1 # Exclude the date column\n    except Exception as e:\n        print(f\"Error reading first ticker file {first_ticker_path}: {e}\")\n        return None, None, None, None\n\n    eod_data = np.zeros([len(tickers), num_days, num_features], dtype=np.float32)\n    masks = np.ones([len(tickers), num_days], dtype=np.float32)\n    ground_truth = np.zeros([len(tickers), num_days], dtype=np.float32) # We're not using this one\n    base_price = np.zeros([len(tickers), num_days], dtype=np.float32)\n\n    for index, ticker in enumerate(tickers):\n        if index % 50 == 0:\n          print(f\"Processed [{index}/{tickers.shape[0]}] tickers\")\n        single_EOD_path = os.path.join(data_path, market_name + '_' + ticker + '_1.csv')\n\n        try:\n            single_df = pd.read_csv(single_EOD_path, header=None)\n            if market_name == 'NASDAQ':\n                single_df = single_df[:-1] # remove the last day since lots of missing data\n\n            # Handle missing values (-1234)\n            single_EOD = single_df.values\n            mask_row_indices, mask_col_indices = np.where(np.abs(single_EOD + 1234) < 1e-8)\n            single_EOD[mask_row_indices, mask_col_indices] = 1.1 # Replace missing values\n\n            # Update masks based on missing closing price\n            missing_close_indices = np.where(np.abs(single_EOD[:, -1] + 1234) < 1e-8)[0]\n            masks[index, missing_close_indices] = 0.0\n\n            eod_data[index, :, :] = single_EOD[:, 1:] # Exclude date column\n            base_price[index, :] = single_EOD[:, -1]\n\n        except Exception as e:\n            print(f\"Error reading ticker file {single_EOD_path}: {e}\")\n            # Mark all days for this ticker as invalid if file reading fails\n            masks[index, :] = 0.0\n\n\n    print('eod data shape:', eod_data.shape)\n    return eod_data, masks, ground_truth, base_price",
   "metadata": {
    "id": "lxx4rTcGrQ51",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.554303Z",
     "iopub.execute_input": "2025-10-29T17:53:29.554772Z",
     "iopub.status.idle": "2025-10-29T17:53:29.564819Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.554746Z",
     "shell.execute_reply": "2025-10-29T17:53:29.563943Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:33.814221Z",
     "start_time": "2025-10-30T13:31:33.808595Z"
    }
   },
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCOPIED FROM THE PAPER\nsource code: https://github.com/fulifeng/Temporal_Relational_Stock_Ranking\n\"\"\"\ndef load_relation_data(relation_file):\n    relation_encoding = np.load(relation_file)\n    print('relation encoding shape:', relation_encoding.shape)\n    rel_shape = [relation_encoding.shape[0], relation_encoding.shape[1]]\n    mask_flags = np.equal(np.zeros(rel_shape, dtype=int),\n                          np.sum(relation_encoding, axis=2))\n    mask = np.where(mask_flags, np.ones(rel_shape) * -1e9, np.zeros(rel_shape))\n    return relation_encoding, mask",
   "metadata": {
    "id": "152QpGtv3cLe",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.565722Z",
     "iopub.execute_input": "2025-10-29T17:53:29.565979Z",
     "iopub.status.idle": "2025-10-29T17:53:29.584380Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.565962Z",
     "shell.execute_reply": "2025-10-29T17:53:29.583828Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:33.860031Z",
     "start_time": "2025-10-30T13:31:33.857448Z"
    }
   },
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "source": "# Loading data",
   "metadata": {
    "id": "FSE-7G93pDs4"
   }
  },
  {
   "cell_type": "code",
   "source": "# market = \"NYSE\"\nmarket = \"NASDAQ\"",
   "metadata": {
    "id": "2UI3iC-ohQfJ",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.586622Z",
     "iopub.execute_input": "2025-10-29T17:53:29.586870Z",
     "iopub.status.idle": "2025-10-29T17:53:29.597891Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.586843Z",
     "shell.execute_reply": "2025-10-29T17:53:29.597176Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:33.903281Z",
     "start_time": "2025-10-30T13:31:33.901638Z"
    }
   },
   "outputs": [],
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "source": "industry_encodings, industry_mask = load_relation_data(dir+f'/relation/sector_industry/{market}_industry_relation.npy')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fowuc2213lyG",
    "outputId": "27ad7c92-3a47-4f23-fbe3-054969e44eb0",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.598625Z",
     "iopub.execute_input": "2025-10-29T17:53:29.598853Z",
     "iopub.status.idle": "2025-10-29T17:53:32.366766Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.598834Z",
     "shell.execute_reply": "2025-10-29T17:53:32.366010Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:34.037499Z",
     "start_time": "2025-10-30T13:31:33.946809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation encoding shape: (1026, 1026, 97)\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "source": "wiki_encodings, wiki_mask = load_relation_data(dir+f'/relation/wikidata/{market}_wiki_relation.npy')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDEWN7RA4Gbt",
    "outputId": "b25d974f-c25b-491f-bbe0-4ddfd7c9e99a",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:32.367567Z",
     "iopub.execute_input": "2025-10-29T17:53:32.367823Z",
     "iopub.status.idle": "2025-10-29T17:53:33.695882Z",
     "shell.execute_reply.started": "2025-10-29T17:53:32.367805Z",
     "shell.execute_reply": "2025-10-29T17:53:33.695144Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:34.092505Z",
     "start_time": "2025-10-30T13:31:34.046055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation encoding shape: (1026, 1026, 43)\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "source": "# Load company names\ntickers = np.loadtxt(dir+f'/{market}_tickers.csv', dtype=str)\nprint('tickers shape (# of companies):', tickers.shape)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W220yLcuM08d",
    "outputId": "68fe3e97-6354-4695-d821-2ef503fa6354",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:33.696692Z",
     "iopub.execute_input": "2025-10-29T17:53:33.696988Z",
     "iopub.status.idle": "2025-10-29T17:53:33.706205Z",
     "shell.execute_reply.started": "2025-10-29T17:53:33.696960Z",
     "shell.execute_reply": "2025-10-29T17:53:33.705625Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:34.102836Z",
     "start_time": "2025-10-30T13:31:34.100088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers shape (# of companies): (1026,)\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "source": "eod_data, eod_masks, eod_ground_truth, eod_base_price = load_EOD_data(dir+\"/2013-01-01\", market, tickers)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwhOJ--P4jKe",
    "outputId": "70e65b50-499e-4abc-af6a-a98b6fdfe52e",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:33.706954Z",
     "iopub.execute_input": "2025-10-29T17:53:33.707134Z",
     "iopub.status.idle": "2025-10-29T17:53:42.849678Z",
     "shell.execute_reply.started": "2025-10-29T17:53:33.707119Z",
     "shell.execute_reply": "2025-10-29T17:53:42.848944Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:34.826564Z",
     "start_time": "2025-10-30T13:31:34.146245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed [0/1026] tickers\n",
      "Processed [50/1026] tickers\n",
      "Processed [100/1026] tickers\n",
      "Processed [150/1026] tickers\n",
      "Processed [200/1026] tickers\n",
      "Processed [250/1026] tickers\n",
      "Processed [300/1026] tickers\n",
      "Processed [350/1026] tickers\n",
      "Processed [400/1026] tickers\n",
      "Processed [450/1026] tickers\n",
      "Processed [500/1026] tickers\n",
      "Processed [550/1026] tickers\n",
      "Processed [600/1026] tickers\n",
      "Processed [650/1026] tickers\n",
      "Processed [700/1026] tickers\n",
      "Processed [750/1026] tickers\n",
      "Processed [800/1026] tickers\n",
      "Processed [850/1026] tickers\n",
      "Processed [900/1026] tickers\n",
      "Processed [950/1026] tickers\n",
      "Processed [1000/1026] tickers\n",
      "eod data shape: (1026, 1245, 5)\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# SUBSAMPLE DATA TO num_companies\n# ============================================================================\n# This cell ensures all data uses the same subset of companies consistently\n\nprint(f\"Subsampling to {num_companies} companies...\")\n\n# Subsample relation data (company x company matrices)\nwiki_encodings = wiki_encodings[:num_companies, :num_companies, :]\nwiki_mask = wiki_mask[:num_companies, :num_companies]\nindustry_encodings = industry_encodings[:num_companies, :num_companies, :]\nindustry_mask = industry_mask[:num_companies, :num_companies]\n\n# Subsample EOD data (reload with subset of tickers)\neod_data, eod_masks, eod_ground_truth, eod_base_price = load_EOD_data(\n    dir + \"/2013-01-01\", \n    market, \n    tickers[:num_companies]\n)\n\nprint(f\"\\nSubsampled data shapes:\")\nprint(f\"  EOD data: {eod_data.shape}\")\nprint(f\"  Industry encodings: {industry_encodings.shape}\")\nprint(f\"  Wiki encodings: {wiki_encodings.shape}\")",
   "metadata": {
    "id": "U1madQ_P7Hq-",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:58:31.973344Z",
     "iopub.execute_input": "2025-10-29T17:58:31.973917Z",
     "iopub.status.idle": "2025-10-29T17:58:32.823635Z",
     "shell.execute_reply.started": "2025-10-29T17:58:31.973896Z",
     "shell.execute_reply": "2025-10-29T17:58:32.822766Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:35.514925Z",
     "start_time": "2025-10-30T13:31:34.831604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampling to 1026 companies...\n",
      "Processed [0/1026] tickers\n",
      "Processed [50/1026] tickers\n",
      "Processed [100/1026] tickers\n",
      "Processed [150/1026] tickers\n",
      "Processed [200/1026] tickers\n",
      "Processed [250/1026] tickers\n",
      "Processed [300/1026] tickers\n",
      "Processed [350/1026] tickers\n",
      "Processed [400/1026] tickers\n",
      "Processed [450/1026] tickers\n",
      "Processed [500/1026] tickers\n",
      "Processed [550/1026] tickers\n",
      "Processed [600/1026] tickers\n",
      "Processed [650/1026] tickers\n",
      "Processed [700/1026] tickers\n",
      "Processed [750/1026] tickers\n",
      "Processed [800/1026] tickers\n",
      "Processed [850/1026] tickers\n",
      "Processed [900/1026] tickers\n",
      "Processed [950/1026] tickers\n",
      "Processed [1000/1026] tickers\n",
      "eod data shape: (1026, 1245, 5)\n",
      "\n",
      "Subsampled data shapes:\n",
      "  EOD data: (1026, 1245, 5)\n",
      "  Industry encodings: (1026, 1026, 97)\n",
      "  Wiki encodings: (1026, 1026, 43)\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "source": "# Graph based Models",
   "metadata": {
    "id": "2aaU7CdApNk_"
   }
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# UTILITY FUNCTIONS - Graph and Data Preparation\n# ============================================================================\n\ndef build_adjacency_matrix(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device):\n    \"\"\"\n    Build normalized adjacency matrix from relation encodings and masks\n    \n    Args:\n        industry_encodings: [num_companies, num_companies, num_relation_types]\n        industry_mask: [num_companies, num_companies] (-1e9 for no relation, 0 for valid)\n        wiki_encodings: [num_companies, num_companies, num_relation_types]\n        wiki_mask: [num_companies, num_companies]\n    \n    Returns:\n        adjacency_matrix: [num_companies, num_companies] - normalized adjacency\n    \"\"\"\n    # Combine relation encodings by summing across relation types\n    industry_adj = torch.sum(industry_encodings, dim=-1) if MODEL_CONFIG['use_industry_relations'] else 0\n    wiki_adj = torch.sum(wiki_encodings, dim=-1) if MODEL_CONFIG['use_wiki_relations'] else 0\n    \n    # Combine both relation types\n    combined_adj = industry_adj + wiki_adj\n    \n    # Apply masks: where mask is -1e9 (no relation), set adjacency to 0\n    combined_mask = industry_mask + wiki_mask\n    combined_adj = torch.where(combined_mask < -1e8, torch.zeros_like(combined_adj), combined_adj)\n    \n    # If not using graph structure, return identity matrix\n    if not MODEL_CONFIG['use_graph_structure']:\n        return torch.eye(combined_adj.shape[0], device=device)\n    \n    # Normalize: row-wise normalization (each row sums to 1)\n    row_sums = combined_adj.sum(dim=1, keepdim=True)\n    adjacency_matrix = combined_adj / (row_sums + 1e-8)\n    \n    return adjacency_matrix.to(device)\n\n\ndef build_separate_adjacency_matrices(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device):\n    \"\"\"\n    Build SEPARATE normalized adjacency matrices for industry and wiki relations\n    Used when separate_edge_weights=True\n    \n    Returns:\n        industry_adj: [num_companies, num_companies]\n        wiki_adj: [num_companies, num_companies]\n    \"\"\"\n    # Build industry adjacency\n    industry_adj = torch.sum(industry_encodings, dim=-1) if MODEL_CONFIG['use_industry_relations'] else torch.zeros_like(industry_mask)\n    industry_adj = torch.where(industry_mask < -1e8, torch.zeros_like(industry_adj), industry_adj)\n    \n    # Build wiki adjacency\n    wiki_adj = torch.sum(wiki_encodings, dim=-1) if MODEL_CONFIG['use_wiki_relations'] else torch.zeros_like(wiki_mask)\n    wiki_adj = torch.where(wiki_mask < -1e8, torch.zeros_like(wiki_adj), wiki_adj)\n    \n    # If not using graph structure, return identity matrices\n    if not MODEL_CONFIG['use_graph_structure']:\n        identity = torch.eye(industry_adj.shape[0], device=device)\n        return identity, identity\n    \n    # Normalize each separately\n    industry_row_sums = industry_adj.sum(dim=1, keepdim=True)\n    industry_adj = industry_adj / (industry_row_sums + 1e-8)\n    \n    wiki_row_sums = wiki_adj.sum(dim=1, keepdim=True)\n    wiki_adj = wiki_adj / (wiki_row_sums + 1e-8)\n    \n    return industry_adj.to(device), wiki_adj.to(device)\n\n\ndef build_graph_shift_operator(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device):\n    \"\"\"\n    Build graph shift operator (symmetric normalized adjacency) for GCN models\n    Using D^(-1/2) * A * D^(-1/2) normalization\n    \n    Returns:\n        graph_shift_operator: [num_companies, num_companies]\n    \"\"\"\n    # Combine relation encodings\n    industry_adj = torch.sum(industry_encodings, dim=-1) if MODEL_CONFIG['use_industry_relations'] else 0\n    wiki_adj = torch.sum(wiki_encodings, dim=-1) if MODEL_CONFIG['use_wiki_relations'] else 0\n    combined_adj = industry_adj + wiki_adj\n    \n    # Apply masks\n    combined_mask = industry_mask + wiki_mask\n    combined_adj = torch.where(combined_mask < -1e8, torch.zeros_like(combined_adj), combined_adj)\n    \n    # If not using graph structure, return identity matrix\n    if not MODEL_CONFIG['use_graph_structure']:\n        return torch.eye(combined_adj.shape[0], device=device)\n    \n    # Symmetric normalization: D^(-1/2) * A * D^(-1/2)\n    degree_matrix = torch.diag(torch.pow(torch.sum(combined_adj, dim=1), -0.5))\n    graph_shift_operator = degree_matrix @ combined_adj.float() @ degree_matrix\n    \n    return graph_shift_operator.to(device)\n\n\ndef prepare_data(eod_data, masks, base_price, device, window_size=20, prediction_horizon=1):\n    \"\"\"\n    Create sliding windows for time series prediction with mask handling\n    \n    Args:\n        eod_data: [num_companies, num_days, num_features]\n        masks: [num_companies, num_days] - 1.0 for valid, 0.0 for missing\n        base_price: [num_companies, num_days] - closing price of stock\n        window_size: Number of historical days to use as input\n        prediction_horizon: Number of days ahead to predict (usually 1)\n    \n    Returns:\n        X: Input windows [num_samples, num_companies, window_size, num_features]\n        y: Target prices [num_samples, num_companies, prediction_horizon]\n        sample_masks: Valid sample indicators [num_samples, num_companies]\n    \"\"\"\n    num_companies, num_days, num_features = eod_data.shape\n    num_samples = num_days - window_size - prediction_horizon + 1\n    \n    X = torch.zeros(num_samples, num_companies, window_size, num_features, device=device)\n    y = torch.zeros(num_samples, num_companies, prediction_horizon, device=device)\n    sample_masks = torch.zeros(num_samples, num_companies, device=device)\n    \n    for i in range(num_samples):\n        X[i] = eod_data[:, i:i+window_size, :]\n        y[i, :, :] = base_price[:, i+window_size:i+window_size+prediction_horizon]\n        \n        # A sample is valid if all days in the window AND the target day are valid\n        window_valid = masks[:, i:i+window_size].min(dim=1)[0]  # [num_companies]\n        target_valid = masks[:, i+window_size:i+window_size+prediction_horizon].min(dim=1)[0]\n        sample_masks[i] = window_valid * target_valid\n    \n    return X, y, sample_masks\n\n\ndef temporal_train_val_test_split(X, y, masks, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    \"\"\"\n    Split data temporally into train/validation/test sets\n    IMPORTANT: Splits based on TIME, not randomly (preserves temporal order)\n    \n    Args:\n        X: [num_samples, num_companies, window_size, num_features]\n        y: [num_samples, num_companies, prediction_horizon]\n        masks: [num_samples, num_companies]\n        train_ratio: Proportion for training (e.g., 0.8 = 80%)\n        val_ratio: Proportion for validation (e.g., 0.1 = 10%)\n        test_ratio: Proportion for test (e.g., 0.1 = 10%)\n    \n    Returns:\n        Dictionary with train/val/test splits for X, y, and masks\n    \"\"\"\n    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n    \n    num_samples = X.shape[0]\n    \n    # Calculate split indices based on time\n    train_end = int(num_samples * train_ratio)\n    val_end = int(num_samples * (train_ratio + val_ratio))\n    \n    # Split data temporally\n    splits = {\n        'X_train': X[:train_end],\n        'y_train': y[:train_end],\n        'masks_train': masks[:train_end],\n        \n        'X_val': X[train_end:val_end],\n        'y_val': y[train_end:val_end],\n        'masks_val': masks[train_end:val_end],\n        \n        'X_test': X[val_end:],\n        'y_test': y[val_end:],\n        'masks_test': masks[val_end:],\n    }\n    \n    # Print split information\n    print(f\"\\nTemporal Data Split:\")\n    print(f\"  Train: samples [0:{train_end}] = {splits['X_train'].shape[0]} timesteps\")\n    print(f\"  Val:   samples [{train_end}:{val_end}] = {splits['X_val'].shape[0]} timesteps\")\n    print(f\"  Test:  samples [{val_end}:{num_samples}] = {splits['X_test'].shape[0]} timesteps\")\n    \n    print(f\"\\n  Valid train samples: {splits['masks_train'].sum().item():.0f} / {splits['masks_train'].numel()}\")\n    print(f\"  Valid val samples:   {splits['masks_val'].sum().item():.0f} / {splits['masks_val'].numel()}\")\n    print(f\"  Valid test samples:  {splits['masks_test'].sum().item():.0f} / {splits['masks_test'].numel()}\")\n    \n    return splits\n\n\ndef adjacency_to_edges(adjacency_matrix, industry_adj=None, wiki_adj=None):\n    \"\"\"\n    Convert adjacency matrix to edge_index and edge_weight for PyTorch Geometric\n    Supports both 1D (combined) and 2D (separate industry/wiki) edge features\n    \n    Args:\n        adjacency_matrix: [num_companies, num_companies] tensor - combined adjacency\n        industry_adj: [num_companies, num_companies] tensor - industry adjacency (optional)\n        wiki_adj: [num_companies, num_companies] tensor - wiki adjacency (optional)\n        \n    Returns:\n        edge_index: [2, num_edges] - edge connectivity\n        edge_weight: [num_edges, 1] or [num_edges, 2] - edge weights\n    \"\"\"\n    adj_np = adjacency_matrix.cpu().numpy()\n    rows, cols = np.where(adj_np > 0)\n    \n    edge_index = torch.tensor(np.stack([rows, cols]), dtype=torch.long)\n    \n    # Check if we need 2D edge features\n    if MODEL_CONFIG['separate_edge_weights'] and industry_adj is not None and wiki_adj is not None:\n        # 2D edge features: [industry_weight, wiki_weight]\n        industry_np = industry_adj.cpu().numpy()\n        wiki_np = wiki_adj.cpu().numpy()\n        \n        industry_weights = industry_np[rows, cols]\n        wiki_weights = wiki_np[rows, cols]\n        \n        edge_weight = torch.tensor(\n            np.stack([industry_weights, wiki_weights], axis=1),  # [num_edges, 2]\n            dtype=torch.float32\n        )\n        print(f\"  Using 2D edge features: [industry, wiki]\")\n    else:\n        # 1D edge features: combined weight\n        edge_weights = adj_np[rows, cols]\n        edge_weight = torch.tensor(edge_weights, dtype=torch.float32).view(-1, 1)  # [num_edges, 1]\n        print(f\"  Using 1D edge features: combined\")\n    \n    return edge_index, edge_weight\n\n\ndef create_batched_edges(edge_index, edge_weight, num_companies, max_batch_size):\n    \"\"\"\n    Pre-compute batched edge_index and edge_weight for fast GAT processing\n    Creates one big graph with disconnected subgraphs for each timestep\n    \n    Args:\n        edge_index: [2, num_edges] - base edge connectivity\n        edge_weight: [num_edges, edge_dim] - base edge weights\n        num_companies: Number of nodes per timestep\n        max_batch_size: Maximum number of timesteps to support\n    \n    Returns:\n        edge_index_batched: [2, max_batch_size * num_edges]\n        edge_weight_batched: [max_batch_size * num_edges, edge_dim]\n    \"\"\"\n    num_edges = edge_index.shape[1]\n    edge_dim = edge_weight.shape[1]\n    \n    # Pre-allocate tensors\n    edge_index_batched = torch.zeros(2, max_batch_size * num_edges, dtype=torch.long, device=edge_index.device)\n    edge_weight_batched = torch.zeros(max_batch_size * num_edges, edge_dim, dtype=torch.float32, device=edge_weight.device)\n    \n    # Fill in edges for each timestep\n    for b in range(max_batch_size):\n        start_idx = b * num_edges\n        end_idx = (b + 1) * num_edges\n        \n        # Offset edge indices by b * num_companies\n        edge_index_batched[:, start_idx:end_idx] = edge_index + (b * num_companies)\n        edge_weight_batched[start_idx:end_idx] = edge_weight\n    \n    return edge_index_batched, edge_weight_batched\n\n\ndef calculate_loss(predictions, targets, masks, criterion):\n    \"\"\"\n    Calculate masked loss (only compute loss on valid samples)\n    \n    Args:\n        predictions: Model predictions [batch, companies, output_dim]\n        targets: Ground truth [batch, companies, output_dim]\n        masks: Valid sample mask [batch, companies]\n        criterion: Loss function (should have reduction='none')\n    \n    Returns:\n        loss: Scalar loss value\n    \"\"\"\n    loss_per_sample = criterion(predictions, targets)\n    masked_loss = loss_per_sample * masks.unsqueeze(-1)\n    num_valid = masks.sum() + 1e-8\n    loss = masked_loss.sum() / num_valid\n    return loss\n\n\nprint(\"Utility functions loaded successfully!\")",
   "metadata": {
    "id": "wgYbWmhHHA3u",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:42.854837Z",
     "iopub.execute_input": "2025-10-29T17:53:42.855015Z",
     "iopub.status.idle": "2025-10-29T17:53:42.866146Z",
     "shell.execute_reply.started": "2025-10-29T17:53:42.855002Z",
     "shell.execute_reply": "2025-10-29T17:53:42.865576Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:35.529859Z",
     "start_time": "2025-10-30T13:31:35.518636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "source": "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True",
   "metadata": {
    "id": "H-6FODpFEYEy",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:42.876889Z",
     "iopub.execute_input": "2025-10-29T17:53:42.877144Z",
     "iopub.status.idle": "2025-10-29T17:53:43.011502Z",
     "shell.execute_reply.started": "2025-10-29T17:53:42.877120Z",
     "shell.execute_reply": "2025-10-29T17:53:43.010747Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:35.883285Z",
     "start_time": "2025-10-30T13:31:35.573982Z"
    }
   },
   "outputs": [],
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# CONVERT DATA TO TENSORS\n# ============================================================================\n\nprint(f\"Converting data to tensors for {num_companies} companies...\")\n\n# Convert to tensors - use the already subsampled data\neod_data_tensor = torch.tensor(eod_data, dtype=torch.float32)\nmasks_tensor = torch.tensor(eod_masks, dtype=torch.float32)\nprice_prediction = torch.tensor(eod_base_price, dtype=torch.float32)\n\n# Relation data tensors\nindustry_encodings_tensor = torch.tensor(industry_encodings, dtype=torch.float32)\nindustry_mask_tensor = torch.tensor(industry_mask, dtype=torch.float32)\nwiki_encodings_tensor = torch.tensor(wiki_encodings, dtype=torch.float32)\nwiki_mask_tensor = torch.tensor(wiki_mask, dtype=torch.float32)\n\nprint(f\"\\nTensor shapes:\")\nprint(f\"  EOD data: {eod_data_tensor.shape}\")\nprint(f\"  Masks: {masks_tensor.shape}\")\nprint(f\"  Price prediction: {price_prediction.shape}\")\nprint(f\"  Industry encodings: {industry_encodings_tensor.shape}\")\nprint(f\"  Wiki encodings: {wiki_encodings_tensor.shape}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:35.981743Z",
     "start_time": "2025-10-30T13:31:35.890715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to tensors for 1026 companies...\n",
      "\n",
      "Tensor shapes:\n",
      "  EOD data: torch.Size([1026, 1245, 5])\n",
      "  Masks: torch.Size([1026, 1245])\n",
      "  Price prediction: torch.Size([1026, 1245])\n",
      "  Industry encodings: torch.Size([1026, 1026, 97])\n",
      "  Wiki encodings: torch.Size([1026, 1026, 43])\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# PREPARE TRAINING DATA WITH TRAIN/VAL/TEST SPLIT\n# ============================================================================\n\nprint(f\"Preparing training data with window_size={window_size}, prediction_horizon={prediction_horizon}...\")\n\n# Build graph structures\nadjacency_matrix = build_adjacency_matrix(\n    industry_encodings_tensor, industry_mask_tensor,\n    wiki_encodings_tensor, wiki_mask_tensor,\n    device=device\n)\n\ngraph_shift_operator = build_graph_shift_operator(\n    industry_encodings_tensor, industry_mask_tensor,\n    wiki_encodings_tensor, wiki_mask_tensor,\n    device=device\n)\n\n# Build separate adjacency matrices if using 2D edge weights\nif MODEL_CONFIG['separate_edge_weights']:\n    industry_adj, wiki_adj = build_separate_adjacency_matrices(\n        industry_encodings_tensor, industry_mask_tensor,\n        wiki_encodings_tensor, wiki_mask_tensor,\n        device=device\n    )\nelse:\n    industry_adj, wiki_adj = None, None\n\n# Prepare temporal data with sliding windows\nX_all, y_all, masks_all = prepare_data(\n    eod_data_tensor, masks_tensor, price_prediction,\n    window_size=window_size,\n    prediction_horizon=prediction_horizon,\n    device=device\n)\n\nprint(f\"\\nFull dataset prepared:\")\nprint(f\"  X_all: {X_all.shape}\")\nprint(f\"  y_all: {y_all.shape}\")\nprint(f\"  masks_all: {masks_all.shape}\")\n\n# Split data temporally into train/val/test\ndata_splits = temporal_train_val_test_split(\n    X_all, y_all, masks_all,\n    train_ratio=train_split,\n    val_ratio=val_split,\n    test_ratio=test_split\n)\n\n# Extract splits for easier access\nX_train = data_splits['X_train']\ny_train = data_splits['y_train']\nmasks_train = data_splits['masks_train']\n\nX_val = data_splits['X_val']\ny_val = data_splits['y_val']\nmasks_val = data_splits['masks_val']\n\nX_test = data_splits['X_test']\ny_test = data_splits['y_test']\nmasks_test = data_splits['masks_test']\n\n# Convert adjacency to edge format for GAT models\nprint(f\"\\nConverting adjacency to edge format...\")\nedge_index, edge_weight = adjacency_to_edges(adjacency_matrix, industry_adj, wiki_adj)\nedge_index = edge_index.to(device)\nedge_weight = edge_weight.to(device)\n\n# Pre-compute batched edges if using batched GAT\nif MODEL_CONFIG['use_batched_gat']:\n    print(f\"\\nPre-computing batched edges for fast GAT processing...\")\n    max_batch_size = X_all.shape[0]  # Use full dataset size\n    edge_index_batched, edge_weight_batched = create_batched_edges(\n        edge_index, edge_weight, num_companies, max_batch_size\n    )\n    print(f\"  Batched edges created for up to {max_batch_size} timesteps\")\n    print(f\"  Edge index batched: {edge_index_batched.shape}\")\n    print(f\"  Edge weight batched: {edge_weight_batched.shape}\")\nelse:\n    edge_index_batched, edge_weight_batched = None, None\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Graph structure:\")\nprint(f\"  Adjacency matrix: {adjacency_matrix.shape}\")\nprint(f\"  Edge index: {edge_index.shape}\")\nprint(f\"  Edge weight: {edge_weight.shape}\")\nprint(f\"  Edge dimension: {edge_weight.shape[1]}D ({'industry+wiki separate' if edge_weight.shape[1] == 2 else 'combined'}) \")\nprint(f\"  Total edges: {edge_index.shape[1]}\")\nprint(f\"{'='*60}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feQ_WQ2JrkPY",
    "outputId": "1708b013-d82a-4ee3-f1c0-e501f50fef1a",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:54:48.397770Z",
     "iopub.execute_input": "2025-10-29T17:54:48.398489Z",
     "iopub.status.idle": "2025-10-29T17:54:48.999323Z",
     "shell.execute_reply.started": "2025-10-29T17:54:48.398465Z",
     "shell.execute_reply": "2025-10-29T17:54:48.998433Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:36.262388Z",
     "start_time": "2025-10-30T13:31:35.985520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data with window_size=20, prediction_horizon=1...\n",
      "\n",
      "Full dataset prepared:\n",
      "  X_all: torch.Size([1225, 1026, 20, 5])\n",
      "  y_all: torch.Size([1225, 1026, 1])\n",
      "  masks_all: torch.Size([1225, 1026])\n",
      "\n",
      "Temporal Data Split:\n",
      "  Train: samples [0:980] = 980 timesteps\n",
      "  Val:   samples [980:1102] = 122 timesteps\n",
      "  Test:  samples [1102:1225] = 123 timesteps\n",
      "\n",
      "  Valid train samples: 1005480 / 1005480\n",
      "  Valid val samples:   125172 / 125172\n",
      "  Valid test samples:  126198 / 126198\n",
      "\n",
      "Converting adjacency to edge format...\n",
      "  Using 2D edge features: [industry, wiki]\n",
      "\n",
      "Pre-computing batched edges for fast GAT processing...\n",
      "  Batched edges created for up to 1225 timesteps\n",
      "  Edge index batched: torch.Size([2, 1570450])\n",
      "  Edge weight batched: torch.Size([1570450, 2])\n",
      "\n",
      "============================================================\n",
      "Graph structure:\n",
      "  Adjacency matrix: torch.Size([1026, 1026])\n",
      "  Edge index: torch.Size([2, 1282])\n",
      "  Edge weight: torch.Size([1282, 2])\n",
      "  Edge dimension: 2D (industry+wiki separate) \n",
      "  Total edges: 1282\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nSimple G-VAR (Graph Vector AutoRegression) for Stock Price Prediction\nCombines temporal dependencies (VAR) with graph structure (GNN)\nUpdated to match the paper's data format\n\"\"\"\n\n# ============================================================================\n# Simple G-Var\n# ============================================================================\n\nclass GVarModel(nn.Module):\n    def __init__(self, input_dim, output_dim, num_companies, device, K=2):\n        \"\"\"\n        Args:\n            input_dim: Number of features * window_size per company\n            output_dim: Prediction dimension (1 for return prediction)\n            num_companies: Number of stocks (e.g., 150)\n            K: Number of graph hops\n        \"\"\"\n        super(GVarModel, self).__init__()\n        self.device = device\n        self.K = K\n        self.num_companies = num_companies\n        self.output_dim = output_dim\n\n        self.graph_layers = nn.ModuleList([\n            nn.Linear(input_dim, 1) for _ in range(K + 1)\n        ])\n\n    def forward(self, x, adjacency_matrix):\n        \"\"\"\n        Args:\n            x: Historical data [batch, num_companies, time_steps, input_dim]\n            adjacency_matrix: Graph structure [num_companies, num_companies]\n        Returns:\n            predictions: [batch, num_companies, output_dim]\n        \"\"\"\n        batch_size = x.shape[0]\n\n        # Step 1: Extract temporal features for each stock independently\n        # Reshape to process all companies' time series\n        x_reshaped = x.view(x.shape[0], x.shape[1], -1)  # [batch, companies, time_steps * features]\n\n        # Compute powers of adjacency matrix: A^0 (self), A^1 (neighbors), A^2 (2-hop), ...\n        S_powers = [torch.eye(self.num_companies, device=adjacency_matrix.device)]\n        for k in range(self.K):\n            S_powers.append(torch.matmul(S_powers[-1], adjacency_matrix))\n\n        # Step 2: Aggregate information from k-hop neighbors\n        output = torch.zeros(x.shape[0], x.shape[1], self.output_dim, device=self.device)\n        for k in range(self.K + 1):\n            # Transform features at each hop level\n            transformed = self.graph_layers[k](x_reshaped)  # [batch, companies, hidden_dim]\n\n            # Aggregate from k-hop neighbors: S^k @ transformed\n            aggregated = torch.matmul(S_powers[k], transformed)  # [batch, companies, hidden_dim]\n            output += aggregated\n\n        return output",
   "metadata": {
    "id": "I0WbMW-lHLXW",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.630009Z",
     "iopub.execute_input": "2025-10-29T17:53:43.630228Z",
     "iopub.status.idle": "2025-10-29T17:53:43.647858Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.630207Z",
     "shell.execute_reply": "2025-10-29T17:53:43.647216Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:36.270848Z",
     "start_time": "2025-10-30T13:31:36.266368Z"
    }
   },
   "outputs": [],
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()\n\ntorch.cuda.memory_allocated()\n\n#import gc\n#gc.collect()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Xzxly4ZFtin",
    "outputId": "cc2f23fb-21b6-43ad-c5c8-ae4d4a0d0e99",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.648698Z",
     "iopub.execute_input": "2025-10-29T17:53:43.649023Z",
     "iopub.status.idle": "2025-10-29T17:53:43.664586Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.649008Z",
     "shell.execute_reply": "2025-10-29T17:53:43.663741Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:36.325694Z",
     "start_time": "2025-10-30T13:31:36.315711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637992448"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# ALTERNATIVE TRAINING: G-VAR Model (Commented out - uncomment to use)\n# ============================================================================\n# Simpler baseline model without graph structure\n#\n# model = GVarModel(\n#     input_dim=num_features * window_size,\n#     output_dim=prediction_horizon,\n#     num_companies=num_companies,\n#     device=device,\n#     K=1\n# ).to(device)\n#\n# criterion = nn.MSELoss(reduction='none')\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n#\n# for epoch in range(epochs):\n#     model.train()\n#     optimizer.zero_grad()\n#     \n#     # Use identity matrix instead of adjacency (no graph structure)\n#     predictions = model(X_train, torch.eye(num_companies, device=device))\n#     \n#     loss_per_sample = criterion(predictions, y_train)\n#     masked_loss = loss_per_sample * train_masks.unsqueeze(-1)\n#     num_valid = train_masks.sum() + 1e-8\n#     loss = masked_loss.sum() / num_valid\n#     \n#     loss.backward()\n#     optimizer.step()\n#     \n#     if (epoch + 1) % 50 == 0:\n#         print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')\n\npass  # Placeholder to keep cell executable",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuT9rVIA8a2q",
    "outputId": "f5e82139-35c1-413c-8120-18e47f62753b",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.665394Z",
     "iopub.execute_input": "2025-10-29T17:53:43.665672Z",
     "iopub.status.idle": "2025-10-29T17:53:43.677059Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.665648Z",
     "shell.execute_reply": "2025-10-29T17:53:43.676246Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:36.365516Z",
     "start_time": "2025-10-30T13:31:36.363315Z"
    }
   },
   "outputs": [],
   "execution_count": 128
  },
  {
   "cell_type": "markdown",
   "source": "# GNN",
   "metadata": {
    "id": "KZVrwD7S5NdX"
   }
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# MODEL DEFINITION: GCN (Graph Convolutional Network)\n# ============================================================================\n\nclass GCNModel(nn.Module):\n    \"\"\"\n    Graph Convolutional Network for stock prediction\n    Uses graph shift operator for spatial aggregation\n    \"\"\"\n    def __init__(self, layers_dim, num_companies, S, device, K=1, L=1):\n        \"\"\"\n        Args:\n            layers_dim: List of (input_dim, output_dim) tuples for each layer\n            num_companies: Number of stocks\n            S: Graph shift operator (normalized adjacency)\n            device: torch device\n            K: Number of graph hops\n            L: Number of GCN layers\n        \"\"\"\n        super(GCNModel, self).__init__()\n        self.device = device\n        self.K = K\n        self.L = L\n        self.num_companies = num_companies\n        self.layers_dim = layers_dim\n        \n        # Compute powers of graph shift operator: S^0, S^1, S^2, ...\n        self.S_powers = [S]\n        for k in range(self.K):\n            self.S_powers.append(self.S_powers[-1] @ S)\n        \n        # GCN layers\n        self.gcn_layer1 = nn.ModuleList([\n            nn.Linear(layers_dim[0][0], layers_dim[0][1]) for _ in range(K)\n        ])\n        self.activation1 = nn.ReLU()\n        \n        self.gcn_layer2 = nn.ModuleList([\n            nn.Linear(layers_dim[1][0], layers_dim[1][1]) for _ in range(K)\n        ])\n        self.activation2 = nn.ReLU()\n    \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Historical data [batch, num_companies, time_steps, input_dim]\n        Returns:\n            predictions: [batch, num_companies, output_dim]\n        \"\"\"\n        batch_size = x.shape[0]\n        x_reshaped = x.view(batch_size, self.num_companies, -1)  # Flatten temporal dimension\n        \n        # First GCN layer with K-hop aggregation\n        x_i = x_reshaped\n        output = torch.zeros(batch_size, self.num_companies, self.layers_dim[0][1], device=self.device)\n        for k in range(self.K):\n            transformed = self.gcn_layer1[k](self.S_powers[k] @ x_i)\n            output += transformed\n        x_i = self.activation1(output)\n        \n        # Second GCN layer with K-hop aggregation\n        output = torch.zeros(batch_size, self.num_companies, self.layers_dim[1][1], device=self.device)\n        for k in range(self.K):\n            transformed = self.gcn_layer2[k](self.S_powers[k] @ x_i)\n            output += transformed\n        x_i = self.activation2(output)\n        \n        return x_i\n\n\nprint(\"GCNModel defined successfully!\")",
   "metadata": {
    "id": "85oRacMq5Ms-",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.677828Z",
     "iopub.execute_input": "2025-10-29T17:53:43.678036Z",
     "iopub.status.idle": "2025-10-29T17:53:43.695288Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.678022Z",
     "shell.execute_reply": "2025-10-29T17:53:43.694576Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:36.415061Z",
     "start_time": "2025-10-30T13:31:36.410032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNModel defined successfully!\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# MODEL DEFINITION: GCN-GAT (Hybrid using Graph Attention)\n# ============================================================================\n\nclass GCNGATModel(nn.Module):\n    \"\"\"\n    Hybrid model using Graph Attention Networks (GAT) for stock prediction\n    Uses attention mechanism to weight neighbor importance\n    \n    Supports:\n    - Batched processing (100-1000x faster)\n    - Optional ReLU activation\n    - 1D or 2D edge features\n    \"\"\"\n    def __init__(self, layers_dim, num_companies, adjacency_matrix, S, device, edge_index, edge_weight, \n                 edge_index_batched=None, edge_weight_batched=None, K=1, L=1):\n        \"\"\"\n        Args:\n            layers_dim: List of (input_dim, output_dim) tuples for each layer\n            num_companies: Number of stocks\n            adjacency_matrix: Adjacency matrix for masking\n            S: Graph shift operator\n            device: torch device\n            edge_index: Edge connectivity [2, num_edges]\n            edge_weight: Edge weights [num_edges, edge_dim]\n            edge_index_batched: Pre-computed batched edges (optional)\n            edge_weight_batched: Pre-computed batched edge weights (optional)\n            K: Number of graph hops\n            L: Number of layers\n        \"\"\"\n        super(GCNGATModel, self).__init__()\n        self.device = device\n        self.K = K\n        self.L = L\n        self.num_companies = num_companies\n        self.layers_dim = layers_dim\n        \n        # Graph structure\n        self.S = S\n        self.adjacency_matrix = adjacency_matrix\n        self.mask = (self.adjacency_matrix == 0)\n        self.edge_index = edge_index\n        self.edge_weight = edge_weight\n        \n        # Batched edges (for fast processing)\n        self.use_batched = MODEL_CONFIG['use_batched_gat'] and edge_index_batched is not None\n        if self.use_batched:\n            self.register_buffer('edge_index_batched', edge_index_batched)\n            self.register_buffer('edge_weight_batched', edge_weight_batched)\n        \n        # Determine edge dimension (1D or 2D)\n        edge_dim = edge_weight.shape[1]\n        \n        # GAT layer: attention-based aggregation\n        self.conv_0 = GATConv(\n            in_channels=layers_dim[0][0], \n            out_channels=layers_dim[0][1], \n            heads=MODEL_CONFIG['num_attention_heads'],\n            concat=False,  # Average the heads\n            dropout=MODEL_CONFIG['dropout'], \n            add_self_loops=True, \n            edge_dim=edge_dim,  # 1 or 2 depending on separate_edge_weights\n            fill_value=0, \n            bias=True\n        )\n        \n        # Optional ReLU activation\n        self.use_relu = MODEL_CONFIG['use_relu_output']\n    \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Historical data [batch, num_companies, time_steps, input_dim]\n        Returns:\n            predictions: [batch, num_companies, output_dim]\n        \"\"\"\n        batch_size = x.shape[0]\n        x_reshaped = x.view(batch_size, self.num_companies, -1)  # Flatten temporal dimension\n        \n        if self.use_batched:\n            # ===== FAST BATCHED PROCESSING =====\n            # Reshape to treat all timesteps as one big graph\n            x_flat = x_reshaped.view(-1, x_reshaped.shape[-1])  # [batch*companies, features]\n            \n            # Use pre-computed batched edges (slice to actual batch size)\n            num_edges_per_timestep = self.edge_index.shape[1]\n            total_edges = batch_size * num_edges_per_timestep\n            \n            edge_idx = self.edge_index_batched[:, :total_edges]\n            edge_wgt = self.edge_weight_batched[:total_edges]\n            \n            # Single GAT forward pass for all timesteps!\n            out = self.conv_0(x_flat, edge_idx, edge_wgt)  # [batch*companies, output_dim]\n            \n            # Reshape back to [batch, companies, output_dim]\n            out = out.view(batch_size, self.num_companies, -1)\n            \n        else:\n            # ===== SLOW SEQUENTIAL PROCESSING (original) =====\n            outputs = []\n            for b in range(batch_size):\n                out_b = self.conv_0(x_reshaped[b], self.edge_index, self.edge_weight)\n                outputs.append(out_b)\n            out = torch.stack(outputs)\n        \n        # Optional ReLU activation (off by default for regression)\n        if self.use_relu:\n            out = F.relu(out)\n        \n        return out\n\n\nprint(\"GCNGATModel defined successfully!\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:31:36.466303Z",
     "start_time": "2025-10-30T13:31:36.461231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNGATModel defined successfully!\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# TRAINING: GCN-GAT Model with Validation and Testing\n# ============================================================================\n\n# Only run if GAT model is selected\nif not MODEL_CONFIG['use_gat']:\n    print(\"GAT model not selected in configuration. Skipping...\")\nelse:\n    # Clear GPU memory\n    torch.cuda.empty_cache()\n    \n    print(f\"{'='*60}\")\n    print(f\"TRAINING GCN-GAT MODEL\")\n    print(f\"{'='*60}\")\n    \n    # Verify all 5 features are being used\n    print(f\"\\nFeature verification:\")\n    print(f\"  Input shape: {X_train.shape}\")\n    print(f\"  Features per timestep: {X_train.shape[3]} (should be {num_features})\")\n    print(f\"  Total input dimension: window_size({window_size}) √ó features({num_features}) = {window_size * num_features}\")\n    assert X_train.shape[3] == num_features, f\"Expected {num_features} features but got {X_train.shape[3]}\"\n    print(f\"  ‚úì All {num_features} features are being used!\")\n    \n    # Initialize model\n    print(f\"\\nInitializing GCN-GAT model...\")\n    model = GCNGATModel(\n        layers_dim=[(num_features * window_size, prediction_horizon)],\n        num_companies=num_companies,\n        adjacency_matrix=adjacency_matrix,\n        S=graph_shift_operator,\n        device=device,\n        edge_index=edge_index,\n        edge_weight=edge_weight,\n        edge_index_batched=edge_index_batched if MODEL_CONFIG['use_batched_gat'] else None,\n        edge_weight_batched=edge_weight_batched if MODEL_CONFIG['use_batched_gat'] else None,\n        K=1,\n        L=1\n    ).to(device)\n    \n    # Training configuration\n    criterion = nn.MSELoss(reduction='none')  # Masked loss\n    optimizer = optim.Adam(\n        model.parameters(), \n        lr=MODEL_CONFIG['learning_rate'],\n        weight_decay=MODEL_CONFIG['weight_decay']\n    )\n    \n    print(f\"\\nModel configuration:\")\n    print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    print(f\"  Learning rate: {MODEL_CONFIG['learning_rate']}\")\n    print(f\"  Weight decay: {MODEL_CONFIG['weight_decay']}\")\n    print(f\"  Dropout: {MODEL_CONFIG['dropout']}\")\n    print(f\"  Attention heads: {MODEL_CONFIG['num_attention_heads']}\")\n    print(f\"  Edge dimension: {edge_weight.shape[1]}D\")\n    print(f\"  ReLU on output: {'Yes' if MODEL_CONFIG['use_relu_output'] else 'No (recommended for regression)'}\")\n    print(f\"  Batched processing: {'Yes (FAST!)' if MODEL_CONFIG['use_batched_gat'] else 'No (slow)'}\")\n    \n    # Training tracking\n    best_val_loss = float('inf')\n    patience_counter = 0\n    train_losses = []\n    val_losses = []\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Starting training for {epochs} epochs...\")\n    print(f\"{'='*60}\\n\")\n    \n    # Training loop\n    for epoch in range(epochs):\n        # ===== TRAINING =====\n        model.train()\n        optimizer.zero_grad()\n        \n        # Forward pass\n        predictions = model(X_train)  # [batch, companies, prediction_horizon]\n        \n        # Calculate masked loss\n        train_loss = calculate_loss(predictions, y_train, masks_train, criterion)\n        \n        # Backward pass\n        train_loss.backward()\n        optimizer.step()\n        \n        train_losses.append(train_loss.item())\n        \n        # ===== VALIDATION =====\n        model.eval()\n        with torch.no_grad():\n            val_predictions = model(X_val)\n            val_loss = calculate_loss(val_predictions, y_val, masks_val, criterion)\n            val_losses.append(val_loss.item())\n        \n        # Print progress\n        if (epoch + 1) % 10 == 0 or epoch == 0:\n            print(f'Epoch [{epoch+1:3d}/{epochs}] | Train Loss: {train_loss.item():.6f} | Val Loss: {val_loss.item():.6f}')\n        \n        # Early stopping check\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss.item()\n            patience_counter = 0\n            # Save best model\n            best_model_state = model.state_dict().copy()\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= early_stopping_patience:\n            print(f\"\\nEarly stopping triggered after {epoch+1} epochs (no improvement for {early_stopping_patience} epochs)\")\n            break\n    \n    # Load best model for final evaluation\n    model.load_state_dict(best_model_state)\n    \n    # ===== FINAL EVALUATION =====\n    print(f\"\\n{'='*60}\")\n    print(f\"FINAL EVALUATION (Best Model)\")\n    print(f\"{'='*60}\")\n    \n    model.eval()\n    with torch.no_grad():\n        # Train set\n        train_predictions = model(X_train)\n        final_train_loss = calculate_loss(train_predictions, y_train, masks_train, criterion)\n        \n        # Validation set\n        val_predictions = model(X_val)\n        final_val_loss = calculate_loss(val_predictions, y_val, masks_val, criterion)\n        \n        # Test set\n        test_predictions = model(X_test)\n        final_test_loss = calculate_loss(test_predictions, y_test, masks_test, criterion)\n    \n    print(f\"\\nFinal MSE Loss:\")\n    print(f\"  Train: {final_train_loss.item():.6f}\")\n    print(f\"  Val:   {final_val_loss.item():.6f}\")\n    print(f\"  Test:  {final_test_loss.item():.6f}\")\n    \n    # Calculate RMSE for interpretability\n    print(f\"\\nFinal RMSE:\")\n    print(f\"  Train: {torch.sqrt(final_train_loss).item():.6f}\")\n    print(f\"  Val:   {torch.sqrt(final_val_loss).item():.6f}\")\n    print(f\"  Test:  {torch.sqrt(final_test_loss).item():.6f}\")\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Training completed!\")\n    print(f\"Configuration used:\")\n    print(f\"  Batched GAT: {MODEL_CONFIG['use_batched_gat']}\")\n    print(f\"  ReLU output: {MODEL_CONFIG['use_relu_output']}\")\n    print(f\"  Separate edge weights: {MODEL_CONFIG['separate_edge_weights']}\")\n    print(f\"{'='*60}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:58:40.470365Z",
     "iopub.execute_input": "2025-10-29T17:58:40.470885Z",
     "iopub.status.idle": "2025-10-29T17:58:40.482898Z",
     "shell.execute_reply.started": "2025-10-29T17:58:40.470862Z",
     "shell.execute_reply": "2025-10-29T17:58:40.482205Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T13:33:46.160035Z",
     "start_time": "2025-10-30T13:31:36.511584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING GCN-GAT MODEL\n",
      "============================================================\n",
      "\n",
      "Feature verification:\n",
      "  Input shape: torch.Size([980, 1026, 20, 5])\n",
      "  Features per timestep: 5 (should be 5)\n",
      "  Total input dimension: window_size(20) √ó features(5) = 100\n",
      "  ‚úì All 5 features are being used!\n",
      "\n",
      "Initializing GCN-GAT model...\n",
      "\n",
      "Model configuration:\n",
      "  Total parameters: 316\n",
      "  Learning rate: 0.001\n",
      "  Weight decay: 0.0\n",
      "  Dropout: 0.0\n",
      "  Attention heads: 3\n",
      "  Edge dimension: 2D\n",
      "  ReLU on output: No (recommended for regression)\n",
      "  Batched processing: Yes (FAST!)\n",
      "\n",
      "============================================================\n",
      "Starting training for 1000 epochs...\n",
      "============================================================\n",
      "\n",
      "Epoch [  1/1000] | Train Loss: 0.104239 | Val Loss: 0.091137\n",
      "Epoch [ 10/1000] | Train Loss: 0.018280 | Val Loss: 0.026094\n",
      "Epoch [ 20/1000] | Train Loss: 0.003518 | Val Loss: 0.005298\n",
      "Epoch [ 30/1000] | Train Loss: 0.003394 | Val Loss: 0.003034\n",
      "Epoch [ 40/1000] | Train Loss: 0.003626 | Val Loss: 0.003338\n",
      "Epoch [ 50/1000] | Train Loss: 0.003307 | Val Loss: 0.003318\n",
      "Epoch [ 60/1000] | Train Loss: 0.003081 | Val Loss: 0.003018\n",
      "Epoch [ 70/1000] | Train Loss: 0.002984 | Val Loss: 0.002975\n",
      "Epoch [ 80/1000] | Train Loss: 0.002943 | Val Loss: 0.002888\n",
      "Epoch [ 90/1000] | Train Loss: 0.002921 | Val Loss: 0.002886\n",
      "Epoch [100/1000] | Train Loss: 0.002906 | Val Loss: 0.002857\n",
      "Epoch [110/1000] | Train Loss: 0.002893 | Val Loss: 0.002851\n",
      "Epoch [120/1000] | Train Loss: 0.002881 | Val Loss: 0.002836\n",
      "Epoch [130/1000] | Train Loss: 0.002869 | Val Loss: 0.002825\n",
      "Epoch [140/1000] | Train Loss: 0.002858 | Val Loss: 0.002814\n",
      "Epoch [150/1000] | Train Loss: 0.002846 | Val Loss: 0.002801\n",
      "Epoch [160/1000] | Train Loss: 0.002834 | Val Loss: 0.002790\n",
      "Epoch [170/1000] | Train Loss: 0.002823 | Val Loss: 0.002778\n",
      "Epoch [180/1000] | Train Loss: 0.002811 | Val Loss: 0.002766\n",
      "Epoch [190/1000] | Train Loss: 0.002799 | Val Loss: 0.002754\n",
      "Epoch [200/1000] | Train Loss: 0.002787 | Val Loss: 0.002742\n",
      "Epoch [210/1000] | Train Loss: 0.002775 | Val Loss: 0.002730\n",
      "Epoch [220/1000] | Train Loss: 0.002763 | Val Loss: 0.002718\n",
      "Epoch [230/1000] | Train Loss: 0.002752 | Val Loss: 0.002706\n",
      "Epoch [240/1000] | Train Loss: 0.002740 | Val Loss: 0.002694\n",
      "Epoch [250/1000] | Train Loss: 0.002728 | Val Loss: 0.002682\n",
      "Epoch [260/1000] | Train Loss: 0.002716 | Val Loss: 0.002670\n",
      "Epoch [270/1000] | Train Loss: 0.002703 | Val Loss: 0.002658\n",
      "Epoch [280/1000] | Train Loss: 0.002691 | Val Loss: 0.002646\n",
      "Epoch [290/1000] | Train Loss: 0.002679 | Val Loss: 0.002633\n",
      "Epoch [300/1000] | Train Loss: 0.002667 | Val Loss: 0.002621\n",
      "Epoch [310/1000] | Train Loss: 0.002655 | Val Loss: 0.002609\n",
      "Epoch [320/1000] | Train Loss: 0.002642 | Val Loss: 0.002596\n",
      "Epoch [330/1000] | Train Loss: 0.002630 | Val Loss: 0.002584\n",
      "Epoch [340/1000] | Train Loss: 0.002618 | Val Loss: 0.002572\n",
      "Epoch [350/1000] | Train Loss: 0.002606 | Val Loss: 0.002559\n",
      "Epoch [360/1000] | Train Loss: 0.002594 | Val Loss: 0.002547\n",
      "Epoch [370/1000] | Train Loss: 0.002581 | Val Loss: 0.002535\n",
      "Epoch [380/1000] | Train Loss: 0.002569 | Val Loss: 0.002523\n",
      "Epoch [390/1000] | Train Loss: 0.002557 | Val Loss: 0.002511\n",
      "Epoch [400/1000] | Train Loss: 0.002545 | Val Loss: 0.002499\n",
      "Epoch [410/1000] | Train Loss: 0.002533 | Val Loss: 0.002487\n",
      "Epoch [420/1000] | Train Loss: 0.002521 | Val Loss: 0.002475\n",
      "Epoch [430/1000] | Train Loss: 0.002509 | Val Loss: 0.002463\n",
      "Epoch [440/1000] | Train Loss: 0.002497 | Val Loss: 0.002451\n",
      "Epoch [450/1000] | Train Loss: 0.002485 | Val Loss: 0.002440\n",
      "Epoch [460/1000] | Train Loss: 0.002473 | Val Loss: 0.002428\n",
      "Epoch [470/1000] | Train Loss: 0.002461 | Val Loss: 0.002416\n",
      "Epoch [480/1000] | Train Loss: 0.002449 | Val Loss: 0.002405\n",
      "Epoch [490/1000] | Train Loss: 0.002437 | Val Loss: 0.002393\n",
      "Epoch [500/1000] | Train Loss: 0.002426 | Val Loss: 0.002381\n",
      "Epoch [510/1000] | Train Loss: 0.002414 | Val Loss: 0.002370\n",
      "Epoch [520/1000] | Train Loss: 0.002402 | Val Loss: 0.002358\n",
      "Epoch [530/1000] | Train Loss: 0.002390 | Val Loss: 0.002347\n",
      "Epoch [540/1000] | Train Loss: 0.002378 | Val Loss: 0.002335\n",
      "Epoch [550/1000] | Train Loss: 0.002366 | Val Loss: 0.002324\n",
      "Epoch [560/1000] | Train Loss: 0.002355 | Val Loss: 0.002313\n",
      "Epoch [570/1000] | Train Loss: 0.002343 | Val Loss: 0.002301\n",
      "Epoch [580/1000] | Train Loss: 0.002331 | Val Loss: 0.002290\n",
      "Epoch [590/1000] | Train Loss: 0.002319 | Val Loss: 0.002278\n",
      "Epoch [600/1000] | Train Loss: 0.002308 | Val Loss: 0.002267\n",
      "Epoch [610/1000] | Train Loss: 0.002296 | Val Loss: 0.002256\n",
      "Epoch [620/1000] | Train Loss: 0.002284 | Val Loss: 0.002244\n",
      "Epoch [630/1000] | Train Loss: 0.002273 | Val Loss: 0.002233\n",
      "Epoch [640/1000] | Train Loss: 0.002261 | Val Loss: 0.002222\n",
      "Epoch [650/1000] | Train Loss: 0.002250 | Val Loss: 0.002211\n",
      "Epoch [660/1000] | Train Loss: 0.002238 | Val Loss: 0.002199\n",
      "Epoch [670/1000] | Train Loss: 0.002227 | Val Loss: 0.002188\n",
      "Epoch [680/1000] | Train Loss: 0.002216 | Val Loss: 0.002177\n",
      "Epoch [690/1000] | Train Loss: 0.002205 | Val Loss: 0.002166\n",
      "Epoch [700/1000] | Train Loss: 0.002194 | Val Loss: 0.002155\n",
      "Epoch [710/1000] | Train Loss: 0.002182 | Val Loss: 0.002144\n",
      "Epoch [720/1000] | Train Loss: 0.002171 | Val Loss: 0.002133\n",
      "Epoch [730/1000] | Train Loss: 0.002161 | Val Loss: 0.002122\n",
      "Epoch [740/1000] | Train Loss: 0.002150 | Val Loss: 0.002111\n",
      "Epoch [750/1000] | Train Loss: 0.002139 | Val Loss: 0.002100\n",
      "Epoch [760/1000] | Train Loss: 0.002128 | Val Loss: 0.002089\n",
      "Epoch [770/1000] | Train Loss: 0.002117 | Val Loss: 0.002079\n",
      "Epoch [780/1000] | Train Loss: 0.002106 | Val Loss: 0.002068\n",
      "Epoch [790/1000] | Train Loss: 0.002095 | Val Loss: 0.002057\n",
      "Epoch [800/1000] | Train Loss: 0.002084 | Val Loss: 0.002046\n",
      "Epoch [810/1000] | Train Loss: 0.002073 | Val Loss: 0.002035\n",
      "Epoch [820/1000] | Train Loss: 0.002063 | Val Loss: 0.002023\n",
      "Epoch [830/1000] | Train Loss: 0.002052 | Val Loss: 0.002012\n",
      "Epoch [840/1000] | Train Loss: 0.002040 | Val Loss: 0.002001\n",
      "Epoch [850/1000] | Train Loss: 0.002029 | Val Loss: 0.001990\n",
      "Epoch [860/1000] | Train Loss: 0.002018 | Val Loss: 0.001978\n",
      "Epoch [870/1000] | Train Loss: 0.002007 | Val Loss: 0.001967\n",
      "Epoch [880/1000] | Train Loss: 0.001996 | Val Loss: 0.001955\n",
      "Epoch [890/1000] | Train Loss: 0.001985 | Val Loss: 0.001944\n",
      "Epoch [900/1000] | Train Loss: 0.001973 | Val Loss: 0.001932\n",
      "Epoch [910/1000] | Train Loss: 0.001962 | Val Loss: 0.001921\n",
      "Epoch [920/1000] | Train Loss: 0.001951 | Val Loss: 0.001909\n",
      "Epoch [930/1000] | Train Loss: 0.001940 | Val Loss: 0.001897\n",
      "Epoch [940/1000] | Train Loss: 0.001928 | Val Loss: 0.001886\n",
      "Epoch [950/1000] | Train Loss: 0.001917 | Val Loss: 0.001874\n",
      "Epoch [960/1000] | Train Loss: 0.001906 | Val Loss: 0.001862\n",
      "Epoch [970/1000] | Train Loss: 0.001894 | Val Loss: 0.001851\n",
      "Epoch [980/1000] | Train Loss: 0.001883 | Val Loss: 0.001839\n",
      "Epoch [990/1000] | Train Loss: 0.001872 | Val Loss: 0.001827\n",
      "Epoch [1000/1000] | Train Loss: 0.001860 | Val Loss: 0.001816\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION (Best Model)\n",
      "============================================================\n",
      "\n",
      "Final MSE Loss:\n",
      "  Train: 0.001859\n",
      "  Val:   0.001816\n",
      "  Test:  0.001975\n",
      "\n",
      "Final RMSE:\n",
      "  Train: 0.043120\n",
      "  Val:   0.042612\n",
      "  Test:  0.044436\n",
      "\n",
      "============================================================\n",
      "Training completed!\n",
      "Configuration used:\n",
      "  Batched GAT: True\n",
      "  ReLU output: False\n",
      "  Separate edge weights: True\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# VISUALIZE TRAINING PROGRESS\n# ============================================================================\n\nif MODEL_CONFIG['use_gat'] and 'train_losses' in locals():\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(12, 5))\n    \n    # Plot losses\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss', alpha=0.7)\n    plt.plot(val_losses, label='Val Loss', alpha=0.7)\n    plt.xlabel('Epoch')\n    plt.ylabel('MSE Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Plot RMSE (more interpretable)\n    plt.subplot(1, 2, 2)\n    plt.plot([torch.sqrt(torch.tensor(l)).item() for l in train_losses], label='Train RMSE', alpha=0.7)\n    plt.plot([torch.sqrt(torch.tensor(l)).item() for l in val_losses], label='Val RMSE', alpha=0.7)\n    plt.xlabel('Epoch')\n    plt.ylabel('RMSE')\n    plt.title('Training and Validation RMSE')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nTraining statistics:\")\n    print(f\"  Best epoch: {val_losses.index(min(val_losses)) + 1}\")\n    print(f\"  Best val loss: {min(val_losses):.6f}\")\n    print(f\"  Final train loss: {train_losses[-1]:.6f}\")\n    print(f\"  Final val loss: {val_losses[-1]:.6f}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T13:33:46.436409Z",
     "start_time": "2025-10-30T13:33:46.307359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training statistics:\n",
      "  Best epoch: 1000\n",
      "  Best val loss: 0.001816\n",
      "  Final train loss: 0.001860\n",
      "  Final val loss: 0.001816\n"
     ]
    }
   ],
   "execution_count": 132
  }
 ]
}
