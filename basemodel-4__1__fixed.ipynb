{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "is5ZiquMgj5j",
    "Nt6BQK32gMN1"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 13424334,
     "sourceType": "datasetVersion",
     "datasetId": 8520408
    }
   ],
   "dockerImageVersionId": 31153,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# Configuration variables\ndir = '/kaggle/input/your-data-folder'  # Adjust this path for your Kaggle setup\nimport os\n\nnum_companies = 150 # max is 1026\nnum_days = 1245\nnum_features = 5\nwindow_size = 20 # if you change this is not changed everywhere yet unfortunately todo\ncalculate_correlation = False\ntrain_batch = 1\nval_batch = 1\nK = 5\nepochs = 20\nval_min_num = 10\nuse_kfold = False\n\nif 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n    print(\"Running on Kaggle!\")\n    dir = '/kaggle/input/rsr-dataset/Data/'\n    train_batch = 32\n    val_batch = 32\n    epochs = 100\n    num_companies = 1026\n    calculate_correlation = True\n\nelse:\n    dir = '/home/study/IdeaProjects/Graph-Machine-Learning/Temporal_RSR/data' # Samuel's directory\n    print(\"Running locally!\")\n    # turn\n\nSAVE_PREPROCESSED_DATA = False  # Set to True to save preprocessed data for faster loading\n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4fHdjEH4tYB",
    "outputId": "488adae8-79e9-44b9-85a0-e6c06b5b3183",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:25.343691Z",
     "iopub.execute_input": "2025-10-29T17:53:25.344255Z",
     "iopub.status.idle": "2025-10-29T17:53:25.353376Z",
     "shell.execute_reply.started": "2025-10-29T17:53:25.344224Z",
     "shell.execute_reply": "2025-10-29T17:53:25.352576Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:44.599279Z",
     "start_time": "2025-10-30T10:05:44.595201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:45.848272Z",
     "start_time": "2025-10-30T10:05:44.664338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%pip install torch-geometric\n",
    "%pip install statsmodels\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1 of /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages/distutils-precedence.pth:\r\n",
      "\r\n",
      "  Traceback (most recent call last):\r\n",
      "    File \"<frozen site>\", line 195, in addpackage\r\n",
      "    File \"<string>\", line 1, in <module>\r\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\r\n",
      "\r\n",
      "Remainder of file ignored\r\n",
      "Requirement already satisfied: torch-geometric in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (2.6.1)\r\n",
      "Requirement already satisfied: aiohttp in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (3.12.15)\r\n",
      "Requirement already satisfied: fsspec in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (2025.9.0)\r\n",
      "Requirement already satisfied: jinja2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: numpy in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (2.0.1)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (7.1.0)\r\n",
      "Requirement already satisfied: pyparsing in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (3.2.5)\r\n",
      "Requirement already satisfied: requests in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (2.32.5)\r\n",
      "Requirement already satisfied: tqdm in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from torch-geometric) (4.67.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (6.6.4)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (0.4.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.21.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from jinja2->torch-geometric) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from requests->torch-geometric) (2025.10.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Error processing line 1 of /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages/distutils-precedence.pth:\r\n",
      "\r\n",
      "  Traceback (most recent call last):\r\n",
      "    File \"<frozen site>\", line 195, in addpackage\r\n",
      "    File \"<string>\", line 1, in <module>\r\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\r\n",
      "\r\n",
      "Remainder of file ignored\r\n",
      "Requirement already satisfied: statsmodels in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (0.14.5)\r\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (2.0.1)\r\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (1.16.2)\r\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (2.3.3)\r\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (1.0.1)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from statsmodels) (25.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/study/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport numpy as np\nimport networkx as nx\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os",
   "metadata": {
    "id": "9j8W6h4rkMKv",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:25.354718Z",
     "iopub.execute_input": "2025-10-29T17:53:25.354874Z",
     "iopub.status.idle": "2025-10-29T17:53:29.553412Z",
     "shell.execute_reply.started": "2025-10-29T17:53:25.354862Z",
     "shell.execute_reply": "2025-10-29T17:53:29.552648Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:47.452473Z",
     "start_time": "2025-10-30T10:05:46.933110Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCOPIED FROM THE PAPER\nsource code: https://github.com/fulifeng/Temporal_Relational_Stock_Ranking\n\"\"\"\ndef load_EOD_data(data_path, market_name, tickers, steps=1):\n    eod_data = []\n    masks = []\n    ground_truth = []\n    base_price = []\n\n    # Determine the expected number of rows based on the first ticker's data\n    first_ticker_path = os.path.join(data_path, market_name + '_' + tickers[0] + '_1.csv')\n    try:\n        first_df = pd.read_csv(first_ticker_path, header=None)\n        num_days = first_df.shape[0] - (1 if market_name == 'NASDAQ' else 0) # Remove last row for NASDAQ\n        num_features = first_df.shape[1] - 1 # Exclude the date column\n    except Exception as e:\n        print(f\"Error reading first ticker file {first_ticker_path}: {e}\")\n        return None, None, None, None\n\n    eod_data = np.zeros([len(tickers), num_days, num_features], dtype=np.float32)\n    masks = np.ones([len(tickers), num_days], dtype=np.float32)\n    ground_truth = np.zeros([len(tickers), num_days], dtype=np.float32) # We're not using this one\n    base_price = np.zeros([len(tickers), num_days], dtype=np.float32)\n\n    for index, ticker in enumerate(tickers):\n        if index % 50 == 0:\n          print(f\"Processed [{index}/{tickers.shape[0]}] tickers\")\n        single_EOD_path = os.path.join(data_path, market_name + '_' + ticker + '_1.csv')\n\n        try:\n            single_df = pd.read_csv(single_EOD_path, header=None)\n            if market_name == 'NASDAQ':\n                single_df = single_df[:-1] # remove the last day since lots of missing data\n\n            # Handle missing values (-1234)\n            single_EOD = single_df.values\n            mask_row_indices, mask_col_indices = np.where(np.abs(single_EOD + 1234) < 1e-8)\n            single_EOD[mask_row_indices, mask_col_indices] = 1.1 # Replace missing values\n\n            # Update masks based on missing closing price\n            missing_close_indices = np.where(np.abs(single_EOD[:, -1] + 1234) < 1e-8)[0]\n            masks[index, missing_close_indices] = 0.0\n\n            eod_data[index, :, :] = single_EOD[:, 1:] # Exclude date column\n            base_price[index, :] = single_EOD[:, -1]\n\n        except Exception as e:\n            print(f\"Error reading ticker file {single_EOD_path}: {e}\")\n            # Mark all days for this ticker as invalid if file reading fails\n            masks[index, :] = 0.0\n\n\n    print('eod data shape:', eod_data.shape)\n    return eod_data, masks, ground_truth, base_price",
   "metadata": {
    "id": "lxx4rTcGrQ51",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.554303Z",
     "iopub.execute_input": "2025-10-29T17:53:29.554772Z",
     "iopub.status.idle": "2025-10-29T17:53:29.564819Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.554746Z",
     "shell.execute_reply": "2025-10-29T17:53:29.563943Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:47.541766Z",
     "start_time": "2025-10-30T10:05:47.458273Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nCOPIED FROM THE PAPER\nsource code: https://github.com/fulifeng/Temporal_Relational_Stock_Ranking\n\"\"\"\ndef load_relation_data(relation_file):\n    relation_encoding = np.load(relation_file)\n    print('relation encoding shape:', relation_encoding.shape)\n    rel_shape = [relation_encoding.shape[0], relation_encoding.shape[1]]\n    mask_flags = np.equal(np.zeros(rel_shape, dtype=int),\n                          np.sum(relation_encoding, axis=2))\n    mask = np.where(mask_flags, np.ones(rel_shape) * -1e9, np.zeros(rel_shape))\n    return relation_encoding, mask",
   "metadata": {
    "id": "152QpGtv3cLe",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.565722Z",
     "iopub.execute_input": "2025-10-29T17:53:29.565979Z",
     "iopub.status.idle": "2025-10-29T17:53:29.584380Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.565962Z",
     "shell.execute_reply": "2025-10-29T17:53:29.583828Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:47.589080Z",
     "start_time": "2025-10-30T10:05:47.586698Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": "# Loading data",
   "metadata": {
    "id": "FSE-7G93pDs4"
   }
  },
  {
   "cell_type": "code",
   "source": "# market = \"NYSE\"\nmarket = \"NASDAQ\"",
   "metadata": {
    "id": "2UI3iC-ohQfJ",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.586622Z",
     "iopub.execute_input": "2025-10-29T17:53:29.586870Z",
     "iopub.status.idle": "2025-10-29T17:53:29.597891Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.586843Z",
     "shell.execute_reply": "2025-10-29T17:53:29.597176Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:47.638784Z",
     "start_time": "2025-10-30T10:05:47.637242Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "industry_encodings, industry_mask = load_relation_data(dir+f'/relation/sector_industry/{market}_industry_relation.npy')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fowuc2213lyG",
    "outputId": "27ad7c92-3a47-4f23-fbe3-054969e44eb0",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:29.598625Z",
     "iopub.execute_input": "2025-10-29T17:53:29.598853Z",
     "iopub.status.idle": "2025-10-29T17:53:32.366766Z",
     "shell.execute_reply.started": "2025-10-29T17:53:29.598834Z",
     "shell.execute_reply": "2025-10-29T17:53:32.366010Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:48.476123Z",
     "start_time": "2025-10-30T10:05:47.688169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation encoding shape: (1026, 1026, 97)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "wiki_encodings, wiki_mask = load_relation_data(dir+f'/relation/wikidata/{market}_wiki_relation.npy')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDEWN7RA4Gbt",
    "outputId": "b25d974f-c25b-491f-bbe0-4ddfd7c9e99a",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:32.367567Z",
     "iopub.execute_input": "2025-10-29T17:53:32.367823Z",
     "iopub.status.idle": "2025-10-29T17:53:33.695882Z",
     "shell.execute_reply.started": "2025-10-29T17:53:32.367805Z",
     "shell.execute_reply": "2025-10-29T17:53:33.695144Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:48.820671Z",
     "start_time": "2025-10-30T10:05:48.484688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation encoding shape: (1026, 1026, 43)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "# Load company names\ntickers = np.loadtxt(dir+f'/{market}_tickers.csv', dtype=str)\nprint('tickers shape (# of companies):', tickers.shape)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W220yLcuM08d",
    "outputId": "68fe3e97-6354-4695-d821-2ef503fa6354",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:33.696692Z",
     "iopub.execute_input": "2025-10-29T17:53:33.696988Z",
     "iopub.status.idle": "2025-10-29T17:53:33.706205Z",
     "shell.execute_reply.started": "2025-10-29T17:53:33.696960Z",
     "shell.execute_reply": "2025-10-29T17:53:33.705625Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:48.829647Z",
     "start_time": "2025-10-30T10:05:48.827161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers shape (# of companies): (1026,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "eod_data, eod_masks, eod_ground_truth, eod_base_price = load_EOD_data(dir+\"/2013-01-01\", market, tickers)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwhOJ--P4jKe",
    "outputId": "70e65b50-499e-4abc-af6a-a98b6fdfe52e",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:33.706954Z",
     "iopub.execute_input": "2025-10-29T17:53:33.707134Z",
     "iopub.status.idle": "2025-10-29T17:53:42.849678Z",
     "shell.execute_reply.started": "2025-10-29T17:53:33.707119Z",
     "shell.execute_reply": "2025-10-29T17:53:42.848944Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:49.775151Z",
     "start_time": "2025-10-30T10:05:48.876861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed [0/1026] tickers\n",
      "Processed [50/1026] tickers\n",
      "Processed [100/1026] tickers\n",
      "Processed [150/1026] tickers\n",
      "Processed [200/1026] tickers\n",
      "Processed [250/1026] tickers\n",
      "Processed [300/1026] tickers\n",
      "Processed [350/1026] tickers\n",
      "Processed [400/1026] tickers\n",
      "Processed [450/1026] tickers\n",
      "Processed [500/1026] tickers\n",
      "Processed [550/1026] tickers\n",
      "Processed [600/1026] tickers\n",
      "Processed [650/1026] tickers\n",
      "Processed [700/1026] tickers\n",
      "Processed [750/1026] tickers\n",
      "Processed [800/1026] tickers\n",
      "Processed [850/1026] tickers\n",
      "Processed [900/1026] tickers\n",
      "Processed [950/1026] tickers\n",
      "Processed [1000/1026] tickers\n",
      "eod data shape: (1026, 1245, 5)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "# Use subset of data for the experiments\nn_companies = 150\n\nwiki_encodings = wiki_encodings[:n_companies, :n_companies, :]\nwiki_mask = wiki_mask[:n_companies, :n_companies]\nindustry_encodings = industry_encodings[:n_companies, :n_companies, :]\nindustry_mask = industry_mask[:n_companies, :n_companies]\n\neod_data, eod_masks, eod_ground_truth, eod_base_price = load_EOD_data(dir+\"/2013-01-01\", \"NASDAQ\", tickers[:n_companies])",
   "metadata": {
    "id": "U1madQ_P7Hq-",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:58:31.973344Z",
     "iopub.execute_input": "2025-10-29T17:58:31.973917Z",
     "iopub.status.idle": "2025-10-29T17:58:32.823635Z",
     "shell.execute_reply.started": "2025-10-29T17:58:31.973896Z",
     "shell.execute_reply": "2025-10-29T17:58:32.822766Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:49.930896Z",
     "start_time": "2025-10-30T10:05:49.827302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed [0/150] tickers\n",
      "Processed [50/150] tickers\n",
      "Processed [100/150] tickers\n",
      "eod data shape: (150, 1245, 5)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": "# Graph based Models",
   "metadata": {
    "id": "2aaU7CdApNk_"
   }
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F",
   "metadata": {
    "id": "wgYbWmhHHA3u",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:42.854837Z",
     "iopub.execute_input": "2025-10-29T17:53:42.855015Z",
     "iopub.status.idle": "2025-10-29T17:53:42.866146Z",
     "shell.execute_reply.started": "2025-10-29T17:53:42.855002Z",
     "shell.execute_reply": "2025-10-29T17:53:42.865576Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:49.937451Z",
     "start_time": "2025-10-30T10:05:49.935441Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# Data Preparation Functions\n# ============================================================================\n\ndef build_adjacency_matrix(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device):\n    \"\"\"\n    Build normalized adjacency matrix from relation encodings and masks\n\n    Args:\n        industry_encodings: [num_companies, num_companies, num_relation_types]\n        industry_mask: [num_companies, num_companies] (-1e9 for no relation, 0 for valid)\n        wiki_encodings: [num_companies, num_companies, num_relation_types]\n        wiki_mask: [num_companies, num_companies]\n\n    Returns:\n        adjacency_matrix: [num_companies, num_companies] - normalized adjacency\n    \"\"\"\n    # Combine relation encodings by summing across relation types\n    industry_adj = torch.sum(industry_encodings, dim=-1)  # [companies, companies]\n    wiki_adj = torch.sum(wiki_encodings, dim=-1)\n\n    # Combine both relation types\n    combined_adj = industry_adj + wiki_adj\n\n    # Apply masks: where mask is -1e9 (no relation), set adjacency to 0\n    combined_mask = industry_mask + wiki_mask\n    combined_adj = torch.where(combined_mask < -1e8, torch.zeros_like(combined_adj), combined_adj)\n\n    # Normalize: row-wise normalization (each row sums to 1)\n    row_sums = combined_adj.sum(dim=1, keepdim=True)\n    adjacency_matrix = combined_adj / (row_sums + 1e-8) # [0, 1)\n\n    return adjacency_matrix.to(device)\n\n\ndef prepare_data(eod_data, masks, base_price, device, window_size=20, prediction_horizon=1):\n    \"\"\"\n    Create sliding windows for time series prediction with mask handling\n\n    Args:\n        eod_data: [num_companies, num_days, num_features]\n        masks: [num_companies, num_days] - 1.0 for valid, 0.0 for missing\n        base_price: [num_companies, num_days] - closing price of stock\n        window_size: Number of historical days to use as input\n        prediction_horizon: Number of days ahead to predict (usually 1)\n\n    Returns:\n        X: Input windows [num_samples, num_companies, window_size, num_features]\n        y: Target returns [num_samples, num_companies, prediction_horizon]\n        sample_masks: Valid sample indicators [num_samples, num_companies]\n    \"\"\"\n    num_companies, num_days, num_features = eod_data.shape\n    num_samples = num_days - window_size - prediction_horizon + 1\n\n    X = torch.zeros(num_samples, num_companies, window_size, num_features, device=device)\n    y = torch.zeros(num_samples, num_companies, prediction_horizon, device=device)\n    sample_masks = torch.zeros(num_samples, num_companies, device=device)\n\n    for i in range(num_samples):\n        X[i] = eod_data[:, i:i+window_size, :]\n        y[i, :, :] = base_price[:, i+window_size : i+window_size+prediction_horizon] #\n\n        # A sample is valid if all days in the window AND the target day are valid\n        window_valid = masks[:, i:i+window_size].min(dim=1)[0]  # [num_companies]\n        target_valid = masks[:, i+window_size : i+window_size+prediction_horizon].min(dim=1)[0]\n        sample_masks[i] = window_valid * target_valid\n\n    return X, y, sample_masks",
   "metadata": {
    "id": "dUaaGygcG3LP",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:42.866844Z",
     "iopub.execute_input": "2025-10-29T17:53:42.867072Z",
     "iopub.status.idle": "2025-10-29T17:53:42.876003Z",
     "shell.execute_reply.started": "2025-10-29T17:53:42.867056Z",
     "shell.execute_reply": "2025-10-29T17:53:42.875243Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:49.987755Z",
     "start_time": "2025-10-30T10:05:49.982482Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True",
   "metadata": {
    "id": "H-6FODpFEYEy",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:42.876889Z",
     "iopub.execute_input": "2025-10-29T17:53:42.877144Z",
     "iopub.status.idle": "2025-10-29T17:53:43.011502Z",
     "shell.execute_reply.started": "2025-10-29T17:53:42.877120Z",
     "shell.execute_reply": "2025-10-29T17:53:43.010747Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:50.286153Z",
     "start_time": "2025-10-30T10:05:50.027752Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Using device:\", device)\n\n# Load data\n# num_companies = eod_data.shape[0] # Change if using subset\nnum_companies = 150\nnum_days = 1245\nnum_features = 5\n\n# Subsample to only use the first num_companies\neod_data = torch.tensor(eod_data[:num_companies])\nmasks = torch.tensor(eod_masks[:num_companies])\nprice_prediction = torch.tensor(eod_base_price[:num_companies])  # FIXED: subsample this too!\n\n# Relation data - subsample both dimensions since it's company x company\nindustry_encodings = torch.tensor(industry_encodings[:num_companies, :num_companies])\nindustry_mask = torch.tensor(industry_mask[:num_companies, :num_companies])\nwiki_encodings = torch.tensor(wiki_encodings[:num_companies, :num_companies])\nwiki_mask = torch.tensor(wiki_mask[:num_companies, :num_companies])\n\nprint(f\"EOD data shape: {eod_data.shape}\")\nprint(f\"Masks shape: {masks.shape}\")\nprint(f\"Ground truth shape: {price_prediction.shape}\")\nprint(f\"Industry encodings shape: {industry_encodings.shape}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feQ_WQ2JrkPY",
    "outputId": "1708b013-d82a-4ee3-f1c0-e501f50fef1a",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:54:48.397770Z",
     "iopub.execute_input": "2025-10-29T17:54:48.398489Z",
     "iopub.status.idle": "2025-10-29T17:54:48.999323Z",
     "shell.execute_reply.started": "2025-10-29T17:54:48.398465Z",
     "shell.execute_reply": "2025-10-29T17:54:48.998433Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:51.879609Z",
     "start_time": "2025-10-30T10:05:50.294390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "EOD data shape: torch.Size([150, 1245, 5])\n",
      "Masks shape: torch.Size([150, 1245])\n",
      "Ground truth shape: torch.Size([150, 1245])\n",
      "Industry encodings shape: torch.Size([150, 150, 97])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "def get_adjacency_matrix(prediction_horizon=1, window_size=100):\n  # Build adjacency matrix from relations\n  adjacency_matrix = build_adjacency_matrix(\n      industry_encodings, industry_mask,\n      wiki_encodings, wiki_mask,\n      device=device\n  )\n  #print(f\"Adjacency matrix shape: {adjacency_matrix.shape}\")\n\n  # Prepare temporal data with masks\n  X_train, y_train, train_masks = prepare_data(\n      eod_data, masks, price_prediction,\n      window_size=window_size,\n      device=device,\n      prediction_horizon=prediction_horizon\n  )\n  #print(f\"Training data: X={X_train.shape}, y={y_train.shape}, masks={train_masks.shape}\")\n\n  return (adjacency_matrix, X_train, y_train, train_masks)",
   "metadata": {
    "id": "L8OFp-5bOq6l",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.623787Z",
     "iopub.execute_input": "2025-10-29T17:53:43.624106Z",
     "iopub.status.idle": "2025-10-29T17:53:43.629262Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.624072Z",
     "shell.execute_reply": "2025-10-29T17:53:43.628534Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:51.956154Z",
     "start_time": "2025-10-30T10:05:51.954003Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": "## Simple G-Var",
   "metadata": {
    "id": "3MKh8eCSgqMu"
   }
  },
  {
   "cell_type": "code",
   "source": "\"\"\"\nSimple G-VAR (Graph Vector AutoRegression) for Stock Price Prediction\nCombines temporal dependencies (VAR) with graph structure (GNN)\nUpdated to match the paper's data format\n\"\"\"\n\n# ============================================================================\n# Simple G-Var\n# ============================================================================\n\nclass GVarModel(nn.Module):\n    def __init__(self, input_dim, output_dim, num_companies, device, K=2):\n        \"\"\"\n        Args:\n            input_dim: Number of features * window_size per company\n            output_dim: Prediction dimension (1 for return prediction)\n            num_companies: Number of stocks (e.g., 150)\n            K: Number of graph hops\n        \"\"\"\n        super(GVarModel, self).__init__()\n        self.device = device\n        self.K = K\n        self.num_companies = num_companies\n        self.output_dim = output_dim\n\n        self.graph_layers = nn.ModuleList([\n            nn.Linear(input_dim, 1) for _ in range(K + 1)\n        ])\n\n    def forward(self, x, adjacency_matrix):\n        \"\"\"\n        Args:\n            x: Historical data [batch, num_companies, time_steps, input_dim]\n            adjacency_matrix: Graph structure [num_companies, num_companies]\n        Returns:\n            predictions: [batch, num_companies, output_dim]\n        \"\"\"\n        batch_size = x.shape[0]\n\n        # Step 1: Extract temporal features for each stock independently\n        # Reshape to process all companies' time series\n        x_reshaped = x.view(x.shape[0], x.shape[1], -1)  # [batch, companies, time_steps * features]\n\n        # Compute powers of adjacency matrix: A^0 (self), A^1 (neighbors), A^2 (2-hop), ...\n        S_powers = [torch.eye(self.num_companies, device=adjacency_matrix.device)]\n        for k in range(self.K):\n            S_powers.append(torch.matmul(S_powers[-1], adjacency_matrix))\n\n        # Step 2: Aggregate information from k-hop neighbors\n        output = torch.zeros(x.shape[0], x.shape[1], self.output_dim, device=self.device)\n        for k in range(self.K + 1):\n            # Transform features at each hop level\n            transformed = self.graph_layers[k](x_reshaped)  # [batch, companies, hidden_dim]\n\n            # Aggregate from k-hop neighbors: S^k @ transformed\n            aggregated = torch.matmul(S_powers[k], transformed)  # [batch, companies, hidden_dim]\n            output += aggregated\n\n        return output",
   "metadata": {
    "id": "I0WbMW-lHLXW",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.630009Z",
     "iopub.execute_input": "2025-10-29T17:53:43.630228Z",
     "iopub.status.idle": "2025-10-29T17:53:43.647858Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.630207Z",
     "shell.execute_reply": "2025-10-29T17:53:43.647216Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:52.005476Z",
     "start_time": "2025-10-30T10:05:52.001957Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()\n\ntorch.cuda.memory_allocated()\n\n#import gc\n#gc.collect()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Xzxly4ZFtin",
    "outputId": "cc2f23fb-21b6-43ad-c5c8-ae4d4a0d0e99",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.648698Z",
     "iopub.execute_input": "2025-10-29T17:53:43.649023Z",
     "iopub.status.idle": "2025-10-29T17:53:43.664586Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.649008Z",
     "shell.execute_reply": "2025-10-29T17:53:43.663741Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:52.054593Z",
     "start_time": "2025-10-30T10:05:52.051137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "# prediction_horizon=1\n# window_size=100\n\n# adjacency_matrix, X_train, y_train, train_masks = get_adjacency_matrix(prediction_horizon, window_size)\n\n# print(\"train_masks.sum():\", train_masks.sum())\n# print(\"train_masks size:\", train_masks.shape[0]*train_masks.shape[1])\n\n\n# # Initialize model\n# model = GVarModel(\n#     input_dim=num_features*window_size,\n#     output_dim=prediction_horizon, # = prediction_horizon\n#     num_companies=num_companies,\n#     device=device,\n#     K=1\n# ).to(device)\n\n# # Training with masked loss\n# criterion = nn.MSELoss(reduction='none')  # Don't reduce yet, we'll apply masks\n# #criterion = nn.L1Loss(reduction='none')  # Don't reduce yet, we'll apply masks\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# epochs = 500\n# for epoch in range(epochs):\n#     model.train()\n#     optimizer.zero_grad()\n\n#     # Forward pass\n#     #predictions = model(X_train, adjacency_matrix)  # [batch, companies, 1]\n#     predictions = model(X_train, torch.eye(num_companies, device=device))  # [batch, companies, 1]\n\n\n#     # Calculate masked loss (only on valid samples)\n#     loss_per_sample = criterion(predictions, y_train)  # [batch, companies, 1]\n#     masked_loss = loss_per_sample * train_masks.unsqueeze(-1)  # Apply mask\n\n#     # Average loss over valid samples only\n#     num_valid = train_masks.sum() + 1e-8\n#     #loss = masked_loss[:,:,model.output_dim-1].sum() / num_valid # Loss only for prediction_horizon day in future (1 day)\n#     loss = masked_loss.sum() / num_valid # Loss for all days up to prediction_horizon\n\n#     # Backward pass\n#     loss.backward()\n#     optimizer.step()\n\n#     if (epoch + 1) % 50 == 0:\n#         print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')\n\n# print(\"Training compled\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuT9rVIA8a2q",
    "outputId": "f5e82139-35c1-413c-8120-18e47f62753b",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.665394Z",
     "iopub.execute_input": "2025-10-29T17:53:43.665672Z",
     "iopub.status.idle": "2025-10-29T17:53:43.677059Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.665648Z",
     "shell.execute_reply": "2025-10-29T17:53:43.676246Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:52.104727Z",
     "start_time": "2025-10-30T10:05:52.102610Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": "# GNN",
   "metadata": {
    "id": "KZVrwD7S5NdX"
   }
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\ndef build_graph_matrix(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device):\n    \"\"\"\n    Build adjacency and degree matrices from relation encodings and masks\n\n    Returns:\n        adjacency_matrix: [num_companies, num_companies]\n        degree_matrix: [num_companies, num_companies]\n    \"\"\"\n    # Combine relation encodings by summing across relation types\n    industry_adj = torch.sum(industry_encodings, dim=-1)  # [companies, companies]\n    wiki_adj = torch.sum(wiki_encodings, dim=-1)\n\n    combined_adj = industry_adj + wiki_adj\n\n    combined_mask = industry_mask + wiki_mask\n    #combined_adj = torch.where(combined_mask < -1e8, torch.zeros_like(combined_adj), combined_adj)\n    degree_matrix = torch.diag(torch.pow(torch.sum(combined_adj, dim=1), -0.5))  # [companies, companies]\n\n    graph_shift_operator =  degree_matrix @ combined_adj.float() @  degree_matrix\n    return graph_shift_operator.to(device)\n\ndef prepare_data(eod_data, masks, base_price, device, window_size=20, prediction_horizon=1):\n    \"\"\"\n    Create sliding windows for time series prediction with mask handling\n\n    Returns:\n        X: Input windows [num_samples, num_companies, window_size, num_features]\n        y: Target returns [num_samples, num_companies, prediction_horizon]\n        sample_masks: Valid sample indicators [num_samples, num_companies]\n    \"\"\"\n    num_companies, num_days, num_features = eod_data.shape\n    num_samples = num_days - window_size - prediction_horizon + 1\n\n    X = torch.zeros(num_samples, num_companies, window_size, num_features, device=device)\n    y = torch.zeros(num_samples, num_companies, prediction_horizon, device=device)\n    sample_masks = torch.zeros(num_samples, num_companies, device=device)\n\n    for i in range(num_samples):\n        X[i] = eod_data[:, i:i+window_size, :]\n        y[i, :, :] = base_price[:, i+window_size : i+window_size+prediction_horizon] #\n\n        # A sample is valid if all days in the window AND the target day are valid\n        window_valid = masks[:, i:i+window_size].min(dim=1)[0]  # [num_companies]\n        target_valid = masks[:, i+window_size : i+window_size+prediction_horizon].min(dim=1)[0]\n        sample_masks[i] = window_valid * target_valid\n\n    return X, y, sample_masks\n\nclass GCNModel(nn.Module):\n    def __init__(self, layers_dim, num_companies, S, device, K=1, L=1):\n        \"\"\"\n        Args:\n            input_dim: Number of features * window_size per company\n            output_dim: Prediction dimension (1 for return prediction)\n            num_companies: Number of stocks (e.g., 150)\n            K: Number of graph hops\n        \"\"\"\n        super(GCNModel, self).__init__()\n        self.device = device\n        self.K = K\n        self.L = L\n        self.num_companies = num_companies\n        self.layers_dim = layers_dim\n\n        # Compute powers of adjacency matrix: A^0 (self), A^1 (neighbors), A^2 (2-hop), ...\n        self.S_powers = [S]\n        for k in range(self.K):\n            self.S_powers.append(self.S_powers[-1] @ S)\n\n        self.gcn_layer1 = nn.ModuleList([\n            nn.Linear(layers_dim[0][0], layers_dim[0][1]) for _ in range(K)\n        ])\n\n        self.activation1 = F.ReLU()\n\n        self.gcn_layer2 = nn.ModuleList([\n            nn.Linear(layers_dim[1][0], layers_dim[1][1]) for _ in range(K)\n        ])\n\n        self.activation2 = F.ReLU()\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Historical data [batch, num_companies, time_steps, input_dim]\n            adjacency_matrix: Graph structure [num_companies, num_companies]\n        Returns:\n            predictions: [batch, num_companies, output_dim]\n        \"\"\"\n        batch_size = x.shape[0]\n        x_reshaped = x.view(x.shape[0], x.shape[1], -1)  # [batch, companies, time_steps * features]\n\n        x_i = x_reshaped\n        output = torch.zeros(batch_size, self.num_companies, self.layers_dim[0][1], device=self.device)\n        for k in range(self.K):\n            # Transform features at each hop level\n            transformed = self.gcn_layer1[k](self.S_powers[k] @ x_i)\n\n            # Aggregate from k-hop neighbors using graph structure\n            output += transformed\n        x_i = self.activation1(output)\n\n        output = torch.zeros(batch_size, self.num_companies, self.layers_dim[1][1], device=self.device)\n        for k in range(self.K):\n            # Transform features at each hop level\n            transformed = self.gcn_layer2[k](self.S_powers[k] @ x_i)\n\n            # Aggregate from k-hop neighbors using graph structure\n            output += transformed\n        x_i = self.activation2(output)\n        return x_i",
   "metadata": {
    "id": "85oRacMq5Ms-",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:43.677828Z",
     "iopub.execute_input": "2025-10-29T17:53:43.678036Z",
     "iopub.status.idle": "2025-10-29T17:53:43.695288Z",
     "shell.execute_reply.started": "2025-10-29T17:53:43.678022Z",
     "shell.execute_reply": "2025-10-29T17:53:43.694576Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:52.157892Z",
     "start_time": "2025-10-30T10:05:52.149971Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": "## GCNGATModel",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "def build_graph_matrix(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device):\n",
    "    \"\"\"\n",
    "    Build adjacency and degree matrices from relation encodings and masks\n",
    "\n",
    "    Returns:\n",
    "        adjacency_matrix: [num_companies, num_companies]\n",
    "        degree_matrix: [num_companies, num_companies]\n",
    "    \"\"\"\n",
    "    # Combine relation encodings by summing across relation types\n",
    "    industry_adj = torch.sum(industry_encodings, dim=-1)  # [companies, companies]\n",
    "    wiki_adj = torch.sum(wiki_encodings, dim=-1)\n",
    "\n",
    "    combined_adj = industry_adj + wiki_adj\n",
    "\n",
    "    combined_mask = industry_mask + wiki_mask\n",
    "    #combined_adj = torch.where(combined_mask < -1e8, torch.zeros_like(combined_adj), combined_adj)\n",
    "    degree_matrix = torch.diag(torch.pow(torch.sum(combined_adj, dim=1), -0.5))  # [companies, companies]\n",
    "\n",
    "    graph_shift_operator =  degree_matrix @ combined_adj.float() @  degree_matrix\n",
    "    return graph_shift_operator.to(device)\n",
    "\n",
    "def prepare_data(eod_data, masks, base_price, device, window_size=20, prediction_horizon=1):\n",
    "    \"\"\"\n",
    "    Create sliding windows for time series prediction with mask handling\n",
    "\n",
    "    Returns:\n",
    "        X: Input windows [num_samples, num_companies, window_size, num_features]\n",
    "        y: Target returns [num_samples, num_companies, prediction_horizon]\n",
    "        sample_masks: Valid sample indicators [num_samples, num_companies]\n",
    "    \"\"\"\n",
    "    num_companies, num_days, num_features = eod_data.shape\n",
    "    # num_companies = 150\n",
    "    num_samples = num_days - window_size - prediction_horizon + 1\n",
    "\n",
    "    X = torch.zeros(num_samples, num_companies, window_size, num_features, device=device)\n",
    "    y = torch.zeros(num_samples, num_companies, prediction_horizon, device=device)\n",
    "    sample_masks = torch.zeros(num_samples, num_companies, device=device)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        X[i] = eod_data[:, i:i+window_size, :]\n",
    "        y[i, :, :] = base_price[:, i+window_size : i+window_size+prediction_horizon] #\n",
    "\n",
    "        # A sample is valid if all days in the window AND the target day are valid\n",
    "        window_valid = masks[:, i:i+window_size].min(dim=1)[0]  # [num_companies]\n",
    "        target_valid = masks[:, i+window_size : i+window_size+prediction_horizon].min(dim=1)[0]\n",
    "        sample_masks[i] = window_valid * target_valid\n",
    "\n",
    "    return X, y, sample_masks\n",
    "\n",
    "class GCNGATModel(nn.Module):\n",
    "    def __init__(self, layers_dim, num_companies, adjacency_matrix, S, device, edge_index, edge_weight, K=1, L=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: Number of features * window_size per company\n",
    "            output_dim: Prediction dimension (1 for return prediction)\n",
    "            num_companies: Number of stocks (e.g., 150)\n",
    "            K: Number of graph hops\n",
    "        \"\"\"\n",
    "        super(GCNGATModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.K = K\n",
    "        self.L = L\n",
    "        self.num_companies = num_companies\n",
    "        self.layers_dim = layers_dim\n",
    "        self.w_linear = nn.Linear(layers_dim[0][0], 15)\n",
    "        self.a = nn.Parameter(torch.randn(size=(2*15, 1))) # size should be 2*out feature size? but what is the out feature size? # todod maybe zero initialize does not work, maybe ones is better\n",
    "        # todo maybe use seed to prevent randomness in initialization\n",
    "        \n",
    "        # todo do i need to initialize the a parameter?\n",
    "        self.S = S\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "        self.mask = (self.adjacency_matrix == 0)\n",
    "        self.conv_0 = GATConv(in_channels=layers_dim[0][0], out_channels=1, heads=2, concat=False, dropout=0.5, add_self_loops=True, edge_dim=1, fill_value=0, bias=True)\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_weight = edge_weight\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Historical data [batch, num_companies, time_steps, input_dim]\n",
    "            adjacency_matrix: Graph structure [num_companies, num_companies]\n",
    "        Returns:\n",
    "            predictions: [batch, num_companies, output_dim]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        x_reshaped = x.view(x.shape[0], x.shape[1], -1)  # [batch, companies, time_steps * features]\n",
    "\n",
    "        x_i = x_reshaped\n",
    "\n",
    "\n",
    "        outputs = []\n",
    "        for b in range(batch_size):\n",
    "            # Process each batch item separately\n",
    "            out = self.conv_0(x_i[b], self.edge_index, self.edge_weight)\n",
    "            out = F.relu(out)\n",
    "            outputs.append(out)\n",
    "\n",
    "        return torch.stack(outputs)\n",
    "\n",
    "        # output = self.conv_0(x_i, self.edge_index, self.edge_weight)\n",
    "        # output = F.softmax(output, dim=-1)\n",
    "        # return output\n",
    "\n",
    "\n",
    "\n",
    "        # h = self.w_linear(x_i) # this is first linear transformation of the x input\n",
    "        # # so now we have all hi*W, but now we need to concatenate all pairs for in the\n",
    "        #\n",
    "        # del x_reshaped\n",
    "        #\n",
    "        # # h contains all node(companies) embeddings\n",
    "        # # first calculate the first part dot procut with a, after the second part\n",
    "        # first_part = h @ self.a[:15, :]\n",
    "        # second_part = h @ self.a[15:, :] # check if i should mention inspiration https://epichka.com/blog/2023/gat-paper-explained/\n",
    "        # # print(first_part.shape)\n",
    "        # # print(second_part.shape)\n",
    "        # partly = first_part+ second_part.mT\n",
    "        # # print(partly.shape)\n",
    "        # e = F.leaky_relu(partly)\n",
    "        # # this above was the a^t[Whi || Whj]\n",
    "        # # print(mask.shape)\n",
    "        # e = e.masked_fill(self.mask, float('-inf'))\n",
    "        # attention = F.softmax(e, dim=-1)\n",
    "        # output = attention @ h\n",
    "        #\n",
    "        # return output\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:58:40.470365Z",
     "iopub.execute_input": "2025-10-29T17:58:40.470885Z",
     "iopub.status.idle": "2025-10-29T17:58:40.482898Z",
     "shell.execute_reply.started": "2025-10-29T17:58:40.470862Z",
     "shell.execute_reply": "2025-10-29T17:58:40.482205Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:10:45.690735Z",
     "start_time": "2025-10-30T10:10:45.684271Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "window_size=30\n",
    "graph_shift_operator = build_graph_matrix(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device)\n",
    "adjacency_matrix = build_adjacency_matrix(\n",
    "      industry_encodings, industry_mask,\n",
    "      wiki_encodings, wiki_mask,\n",
    "      device=device\n",
    "  )\n",
    "X_train, y_train, train_masks = prepare_data(\n",
    "    eod_data=eod_data,\n",
    "    masks=masks,\n",
    "    base_price=price_prediction,\n",
    "    device=device,\n",
    "    window_size=window_size)\n",
    "\n",
    "def adjacency_to_edges(adjacency_matrix):\n",
    "    \"\"\"Convert adjacency matrix to edge_index and edge_weight\"\"\"\n",
    "    adj_np = adjacency_matrix.cpu().numpy()\n",
    "    rows, cols = np.where(adj_np > 0)\n",
    "    edge_weights = adj_np[rows, cols]\n",
    "    edge_index = torch.tensor(np.stack([rows, cols]), dtype=torch.long) # todo check if this is the formatting that is needed\n",
    "    edge_weight = torch.tensor(edge_weights, dtype=torch.float32).view(-1, 1) # todo check if this is correctly formatted for the model\n",
    "    return edge_index, edge_weight\n",
    "    # [[1,2], [3,6], [] ]\n",
    "\n",
    "    # Convert adjacency matrix to edge representation\n",
    "edge_index, edge_weight = adjacency_to_edges(adjacency_matrix)\n",
    "edge_index = edge_index.to(device)\n",
    "edge_weight = edge_weight.to(device)\n",
    "\n",
    "# Initialize model\n",
    "model = GCNGATModel(\n",
    "    layers_dim=[(num_features*window_size, 15), (15, 1)],\n",
    "    num_companies=num_companies,\n",
    "    adjacency_matrix=adjacency_matrix,\n",
    "    S=graph_shift_operator,\n",
    "    device=device,\n",
    "    edge_index=edge_index,\n",
    "    edge_weight=edge_weight,\n",
    "    K=1,\n",
    "    L=1\n",
    ").to(device)\n",
    "\n",
    "# Training with masked loss\n",
    "criterion = nn.MSELoss(reduction='none')  # Don't reduce yet, we'll apply masks\n",
    "#criterion = nn.L1Loss(reduction='none')  # Don't reduce yet, we'll apply masks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    #predictions = model(X_train, adjacency_matrix)  # [batch, companies, 1]\n",
    "    predictions = model(X_train)  # [batch, companies, 1]\n",
    "\n",
    "    # Calculate masked loss (only on valid samples)\n",
    "    loss_per_sample = criterion(predictions, y_train)  # [batch, companies, 1]\n",
    "    masked_loss = loss_per_sample * train_masks.unsqueeze(-1)  # Apply mask\n",
    "\n",
    "    # Average loss over valid samples only\n",
    "    num_valid = train_masks.sum() + 1e-8\n",
    "    #loss = masked_loss[:,:,model.output_dim-1].sum() / num_valid # Loss only for prediction_horizon day in future (1 day)\n",
    "    loss = masked_loss.sum() / num_valid # Loss for all days up to prediction_horizon\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')\n",
    "\n",
    "print(\"Training complted\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:58:43.304831Z",
     "iopub.execute_input": "2025-10-29T17:58:43.305467Z",
     "iopub.status.idle": "2025-10-29T17:58:43.329410Z",
     "shell.execute_reply.started": "2025-10-29T17:58:43.305444Z",
     "shell.execute_reply": "2025-10-29T17:58:43.328527Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:12:51.100294Z",
     "start_time": "2025-10-30T10:10:47.134310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.328155\n",
      "Epoch [20/1000], Loss: 0.244687\n",
      "Epoch [30/1000], Loss: 0.148993\n",
      "Epoch [40/1000], Loss: 0.142930\n",
      "Epoch [50/1000], Loss: 0.127529\n",
      "Epoch [60/1000], Loss: 0.123200\n",
      "Epoch [70/1000], Loss: 0.119215\n",
      "Epoch [80/1000], Loss: 0.115542\n",
      "Epoch [90/1000], Loss: 0.111611\n",
      "Epoch [100/1000], Loss: 0.107769\n",
      "Epoch [110/1000], Loss: 0.104803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 67\u001B[39m\n\u001B[32m     64\u001B[39m loss = masked_loss.sum() / num_valid \u001B[38;5;66;03m# Loss for all days up to prediction_horizon\u001B[39;00m\n\u001B[32m     66\u001B[39m \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     68\u001B[39m optimizer.step()\n\u001B[32m     70\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (epoch + \u001B[32m1\u001B[39m) % \u001B[32m10\u001B[39m == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages/torch/_tensor.py:581\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    571\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    572\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    573\u001B[39m         Tensor.backward,\n\u001B[32m    574\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m         inputs=inputs,\n\u001B[32m    580\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    582\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    583\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/Graph-Machine-Learning/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    823\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    826\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    827\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "# window_size=30\n# graph_shift_operator = build_graph_matrix(industry_encodings, industry_mask, wiki_encodings, wiki_mask, device)\n# X_train, y_train, train_masks = prepare_data(\n#     eod_data=eod_data,\n#     masks=masks,\n#     base_price=price_prediction,\n#     device=device,\n#     window_size=window_size)\n\n# # Initialize model\n# model = GCNModel(\n#     layers_dim=[(num_features*window_size, 15), (15, 1)],\n#     num_companies=num_companies,\n#     S=graph_shift_operator,\n#     device=device,\n#     K=1,\n#     L=1\n# ).to(device)\n\n# # Training with masked loss\n# criterion = nn.MSELoss(reduction='none')  # Don't reduce yet, we'll apply masks\n# #criterion = nn.L1Loss(reduction='none')  # Don't reduce yet, we'll apply masks\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# epochs = 1000\n# for epoch in range(epochs):\n#     model.train()\n#     optimizer.zero_grad()\n\n#     # Forward pass\n#     #predictions = model(X_train, adjacency_matrix)  # [batch, companies, 1]\n#     predictions = model(X_train)  # [batch, companies, 1]\n\n\n#     # Calculate masked loss (only on valid samples)\n#     loss_per_sample = criterion(predictions, y_train)  # [batch, companies, 1]\n#     masked_loss = loss_per_sample * train_masks.unsqueeze(-1)  # Apply mask\n\n#     # Average loss over valid samples only\n#     num_valid = train_masks.sum() + 1e-8\n#     #loss = masked_loss[:,:,model.output_dim-1].sum() / num_valid # Loss only for prediction_horizon day in future (1 day)\n#     loss = masked_loss.sum() / num_valid # Loss for all days up to prediction_horizon\n\n#     # Backward pass\n#     loss.backward()\n#     optimizer.step()\n\n#     if (epoch + 1) % 10 == 0:\n#         print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')\n\n# print(\"Training complted\")",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aFoJLinAlKA",
    "outputId": "b17c36dc-6da8-4c46-f9f0-45428e42f499",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-29T17:53:47.869140Z",
     "iopub.status.idle": "2025-10-29T17:53:47.869353Z",
     "shell.execute_reply.started": "2025-10-29T17:53:47.869253Z",
     "shell.execute_reply": "2025-10-29T17:53:47.869262Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-30T10:05:53.746418200Z",
     "start_time": "2025-10-29T22:04:39.498455Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  }
 ]
}
